\thispagestyle{fancy2}

ここでは，第\ref{chap:introduction}章で述べた位置情報付き一細胞分取システムを踏まえ，AIを組み込んだシステム（以下AIシステム）の取り組むべきタスクを明確にし，問題設定として定式化を行う．まずはじめに，リアルタイム複数物体追跡を行うことによって位置情報付き一細胞分取システムの目的が達成されることを述べ，そのあとにAIシステムの入力と出力について詳細に議論する（\ref{sec:ai_system}節）．そしてそれらをもとに，問題設定をより一般的なものに解釈しながら定式化を行う（\ref{sec:setting_fomulization}節）．また最後には，これらの問題に対して関連する研究について述べる（\ref{sec:related_works}節）．

\section{位置情報付き一細胞分取システムにおけるAIシステム}

\label{sec:ai_system}
位置情報付き一細胞分取システムは，プロトプラスト化した細胞を一つずつ収集し，かつそれらの細胞すべてについてプロトプラスト化する以前の根における領域を特定するAI・ロボットシステムであった．このシステムには，一定時間内で収集できる細胞数を増やしたり，収集の失敗をなるべく削減したりするために，効率性や正確性なども求められる．そのためAIシステムが求められているタスクは，以下の二つである．
\begin{enumerate}[label=(\arabic*)]
    \item 収集のためにロボットが向かうべき位置を正確かつリアルタイムに示すこと．
    \item 収集した細胞のプロトプラスト化以前の領域を正確に特定すること．
\end{enumerate}

これらのタスクを達成するために，本システムではまず，プロトプラスト化が起きている根全体を顕微鏡でリアルタイム撮影し，時系列画像データを得る．そしてこの時系列画像データを入力として，AIシステムではすべての細胞を対象とした細胞追跡を行う．まず(1)のタスクを達成するためには，最新の顕微鏡画像から細胞の位置を検出・推定すればよい．(2)についてはまず，ある時刻の画像におけるある細胞が，別時刻の画像におけるどの細胞であるかを，細胞追跡によって対応付ける．そしてある対象細胞について，はじめに検出された位置を確認すれば達成できる．

以降の項では，AIシステムに入力される時系列画像データおよび出力されるデータについて詳細を述べる．

    \subsection{共焦点顕微鏡から得られる4次元データ}
    \label{subsec:input_from_confocal_microscope}

    細胞のプロトプラスト化は酵素溶液処理によって実施され，プロトプラスト化した細胞は流体環境にさらされるため三次元空間を遊離する．すなわち細胞の追跡を行うためには，三次元空間を認識できる顕微鏡を使用しなければならない．そこで本システムでは，共焦点顕微鏡\cite{paddock2000principles}を使用し，三次元空間を特定の高さでスライスした二次元画像を複数の高さで得ることで三次元空間を認識する．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/confocal.pdf}
        \caption[共焦点顕微鏡の概略図]{共焦点顕微鏡の概略図（\cite{paddock2000principles}をもとに著者が作成）．緑色の光は焦点面で反射し，共役するピンホールを抜けて検出器に入る．一方赤色の光は焦点面より遠い位置で反射しているために，ピンホールを抜けられず検出されない．}
        \label{fig:confocal_microscope}
    \end{figure}

    共焦点顕微鏡は，焦点と共役する位置にピンホールを置くことで焦点外で発生した光を排除し，対象物体の光学断面像（以降スライスと呼ぶ）を得ることができる顕微鏡である（図\ref{fig:confocal_microscope}）．また顕微鏡のステージの高さを動かすことで，さまざまな高さにおけるスライスを取得することができる．

    本システムでは，追跡対象空間の高さの上限および下限，そして撮影を行う焦点距離の間隔を設定し，下限から上限までの複数の二次元タイムラプス画像を取得する．そして上限に達したらまた下限の位置に戻り，撮影を継続する．この操作によって，水平方向の二次元，スライスする高さの一次元，時間の一次元を足した四次元データが取得できる．ただしこの操作によって得られる高さが異なる二次元画像は，完全に同じ時刻には取得されないことに注意されたい．この時間差については次項で議論する．

    \subsection{時間・空間的トレードオフと細胞の位置予測}

    ここでは議論を容易にするため，複数のスライスを撮影し続けた場合に，同じの高さにおけるスライスが再び撮影されるまでにかかる時間をフレーム間隔と呼ぶことにする．また撮影を行う焦点面高さの間隔をスライス間隔と呼ぶことにする．

    AIシステムの役割の一つ目は，ロボットを収集したい細胞の位置に向かわせるために，リアルタイムかつ正確にその位置を出力することであった．もし仮にフレーム間隔およびスライス間隔を同時にかつ十分に小さくできるとすると，この役割は非常に簡単に達成することができる．フレーム間隔が十分に小さければ，ロボットが収集をするその瞬間まで細胞の位置を知ることができ，位置ズレを起こすことがない．またスライス間隔が大きい場合には細胞の高さを正確に推定することが困難になるが，十分に小さければその問題も生じない．

    しかしながらプロトプラスト化した細胞の検出や遊離前の細胞領域の特定のためには高解像度の顕微鏡画像を要し，この撮影にかかる時間が本実験で用いている機器でも無視できない時間となっている．実際この機器では，二次元画像を1枚撮影するのに約1秒の時間を要している．これにより，フレーム間隔とスライス間隔を同時に小さくすることは不可能になる．例えば，植物の根の高さがプロトプラスト化した細胞の大きさの10倍程度であった場合は，細胞10個分ほど高さ方向に運動する可能性があるため，少なくともスライスは10枚以上取得するのが妥当である．この場合にはフレーム間隔が約10秒になり，細胞が大きな速度を持っている場合には大きな位置ズレを起こす．またフレーム間隔を上げる場合にはスライス間隔が大きくなり，連続するスライスの高さの間に入り込んだ細胞を検出できない．

    以上の議論より二次元画像における各細胞の最新情報はリアルタイム性に欠けるため，AIシステムによる細胞の状態予測を行い，ロボットの収集に利用する．ここでの状態とは，細胞の位置に加え，速度や細胞の大きさなどの物理量を含む．ある時刻における位置予測のみでは収集方法の柔軟性に欠けるため，速度なども推定し，より効率的な細胞収集に利用する．

    \subsection{遊離前の細胞領域との対応付け}

    位置情報付き一細胞分取システムでは，遊離前の細胞領域を特定することを目的の一つとしていた．ここで重要視されることは，隣接する細胞がどの細胞であるかが分かることである．これを達成するためには，各細胞の領域を${(x, y, z)} \in \mathbb{R}^3$の集合で表されるような点群で表現する手法が適している．これを達成するためには，ビットマップ形式の画像に対して，各ピクセルがどの細胞に所属するかをラベリングすればよい．

    上記のようなタスクはインスタンスセグメンテーション\cite{hafiz2020survey}と呼ばれる．画像に映る各人物や各物体はインスタンスと呼ばれ，同じクラス（例えば人間や犬など）であったとしても，図\ref{fig:instance_segmentation_and_matching}（左）のように別の領域として検出される．ただしここでは簡易化のために二次元画像を入力された場合の結果を示していることに注意されたい．

    しかしながら，本問題設定にインスタンスセグメンテーションを適用してリアルタイム処理を行うことは難しい．繰り返すように領域特定の目的は，各細胞に対して，他の細胞，特に隣接する細胞とどのような位置関係にあるかを知ることである．そのため図\ref{fig:protoplast_and_main_system}（左）のような画像から，すべての細胞領域を見逃すことなくかつ正確に検出しなければならない．一方でインスタンスセグメンテーションのstate-of-the-artであるYOLACT\cite{Bolya_2019_ICCV}でさえ，30FPSですべての領域を正確に特定することは難しい．また前節で述べた通り，本研究におけるフレーム間隔はだいたい$n_s$秒のオーダーであるため，FPSは大きくても1以下であり，さらなる精度の低下を招くことは想像に難くない．

    以上の議論よりAIシステムでは，遊離している細胞のみを追跡対象とし，オフラインで処理された領域情報との対応付けを事後的に行うことで，遊離前の領域特定を達成する（図\ref{fig:instance_segmentation_and_matching}（右））．一般的に，後述する物体検出であれば，高速に物体の位置を検出することができる．そのため追跡時には物体検出によって遊離した細胞のみを検出し，事後的にインスタンスセグメンテーションを画像データに適用する．そして遊離した細胞のはじめの位置とインスタンスセグメンテーションの結果を比較することで，遊離した各細胞の遊離前領域を特定する．

    \begin{figure}[t]
        \centering
        \begin{subfigure}[b]{.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{fig/segmentation.pdf}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{fig/segmentation_matching.pdf}
        \end{subfigure}
        \caption[インスタンスセグメンテーションと遊離直後位置との対応付け]{インスタンスセグメンテーションと遊離直後位置との対応付け．（左）各個体や各人物はインスタンスと呼ばれ，図のように別領域として検出される．（右）左の画像はインスタンスセグメンテーションの結果であり，右の図は物体検出の結果である．同じ色同士が同じ個体として対応付けされている．}
        \label{fig:instance_segmentation_and_matching}
    \end{figure}

\section{問題設定の一般化および定式化}
\label{sec:setting_fomulization}

この節では，前節で述べたAIシステムの入力データや出力データの定式化を行う．また提案手法の汎用性を確保するために，酵素溶液という流体環境中で遊離する細胞を，相互作用がなく正規性を持った外力ノイズ環境下における球体として一般化する．

まずは，酵素溶液中を遊離している細胞の定式化を行う．図\ref{fig:protoplast_and_main_system}（左）に見られるように，根から遊離した細胞は球体としてみなせる．よって各細胞のある時刻$t$における位置を表した状態変数$\bm{s}(t)$は，
\begin{equation}
    \label{eq:continous_state_vector}
    \bm{s}(t) = \left[x(t), y(t), z(t), r(t)\right]^{\top}
\end{equation}
と表せる．ここで$x(t),y(t),z(t)$は時刻$t$における三次元位置，$r(t)$は時刻$t$における遊離した細胞の半径を表す．

また追跡の対象となる空間を$\Omega = \left[0, \ell\right]^3$と表す．ただし$\ell$は空間の広さを表す実数である．先程の状態変数$\bm{s}(t)$を用いて，時刻$t$で対象空間内にある細胞の集合$S(t)$を，
\begin{equation}
    \label{eq:set_of_cells_at_time}
    S(t) = \left\{\bm{s}(t)^{(i)} \mid i \in 1,2,\dots,n(t)\right\}
\end{equation}
と表す．ここで$n(t)$は，時刻$t$において対象空間$\Omega$内に存在する細胞数である．

次に，共焦点顕微鏡から得られる複数の二次元画像の定式化を行う．共焦点顕微鏡が一枚の二次元画像の取得にかかる時間を$t_c$，対象空間をスライスする平面数を$n_s$とする．このとき，前節で述べたフレーム間隔を$\delta t$，スライス間隔を$\delta z$とすると，
\begin{equation}
    \label{eq:delta_time_and_z}
    \begin{aligned}
        \delta & t = n_s  t_c ,
        \\ \delta & z = \frac{\ell}{n_s - 1}
    \end{aligned}
\end{equation}
が成り立つ．（これらの式から，対象空間の広さ$\ell$と二次元画像の取得にかかる時間$t_c$が定数であれば，スライスする平面数$n_s$によってフレーム間隔とスライス間隔のトレードオフが生じることが分かる．）

ここまで用いた時刻$t$は連続的な時刻を表すため，これとは別に離散的な時刻$\tau$を導入し，この各離散時刻で$n_s$枚の二次元画像を取得するとする．さらに$z = 0$に焦点を合わせた二次元画像をはじめに取得するとし，特に$t = 0$のときこの離散時刻は$\tau = 0$であるとする．このとき，離散時刻$\tau$に取得される$n_s$枚の画像群$\mathcal{X}_{\tau}$を，
\begin{equation}
    \label{eq:sliced_images}
    \begin{aligned}
        & \mathcal{X}_{\tau} = \left\{X_{\tau, s} \mid s \in \left\{1, 2, \dots, n_s\right\}\right\},
        \\ & \textbf{where } X_{\tau, s} \in \mathbb{R}^{W \times H \times 3},
    \end{aligned}
\end{equation}
と表す．ここで$s$は，どの焦点面であるかを示すスライスのインデックスであり，対象領域の$\Omega$において$z = 0$の平面が$s=1$，$z = \ell$の平面が$s=n_s$に相当する．また$X_{\tau, s}$は，離散時刻$\tau$に$s = 1$の二次元画像が取得された$(s - 1) t_c$後に$z = (s - 1) \delta z$の平面で取得された二次元画像である．また$W$は画像の幅，$H$は高さ，$3$はRGBに対応している．

ある平面でスライスされた球体は，二次元画像に円領域として現れる．ある時刻$t$にある高さ$z$でスライスされた球体$\bm{s}(t)$の画像上での半径$r_{z}(t)$は，
\begin{equation}
    \label{eq:appearant_radius}
    r_{z}^{\text{app}}(t) = 
    \begin{cases}
        \sqrt{r(t)^2 - \left((s - 1)\delta z - z(t)\right)^2}, & \textbf{when } r(t) \geq \left|(s - 1)\delta z - z(t)\right|,
        \\ \text{None}, & \textbf{otherwise}
    \end{cases}
\end{equation}
と表されるため，二次元画像$X_{\tau, s}$に対する上述の円領域$R$は，
\begin{equation}
    \label{eq:circle_region}
    \left\{ (x, y) \left| ~ 
        \begin{aligned}
            &(x - x(t))^2 + (y - y(t))^2 \leq r_z^{\text{app}}(t),
            \\ & (x, y) \in [0, \ell]^2,
            \\ & r(t) > \left|z(t) - z\right|
        \end{aligned}
    \right.
    \right\}
\end{equation}
で表される．ただしここでは，$t = \tau \delta t + s t_c, ~ z = (s -1 ) \delta z$である．

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/slicing.pdf}
    \caption[共焦点顕微鏡が出力する複数の二次元画像]{共焦点顕微鏡が出力する複数の二次元画像．ここでは$n_s=10$の例を示している．また本論文では高さが最も低い位置を$s=1$のスライスとし，反対に最も高い位置を$s=n_s$のスライスとしている．}
    \label{fig:sliced_image}
\end{figure}

最後に，AIシステムが出力する，細胞の状態予測と遊離直後の細胞の位置推定について定式化を行う，ここまでの定式化では，細胞の状態を連続的な時刻$t$で表される状態変数$\bm{s}(t)$で表してきたが，実際にこの関数を求めることは非常に難しい．そこで本問題設定では，離散的な時刻$\tau$における細胞の状態変数$\bm{s}_{\tau}$を新たに導入する．

離散時刻$\tau$における状態変数$\bm{s}_{\tau}$の中身は，連続時刻$t$における状態変数$\bm{s}(t)$のように位置情報のみにすると，不十分である．なぜならば，ある単一の時刻$\tau$には有限の時間$\delta t$が存在し，その間に細胞の挙動も大きく変わる可能性があるためである．よって離散的な状態変数$\bm{s}_{\tau}$は速度を表す変数$(\dot{x}, \dot{y}, \dot{z})$も加えて，
\begin{equation}
    \label{eq:discreted_state_vector}
    \bm{s}_{\tau} = \left[x_{\tau}, \dot{x}_{\tau}, y_{\tau}, \dot{y}_{\tau}, z_{\tau}, \dot{z}_{\tau}, r_{\tau}\right]^{\top}
\end{equation}
とする．ここで$\dot{A}$は連続的な時刻に関する一回微分$dA/dt$を表す．また本論文では問題設定の簡易化のため，細胞の状態の表現においては，加速度は考慮しないものとする．この状態変数の導入に伴い以降では，AIシステムの役割である位置予測および位置特定を，状態予測および状態推定と呼称する．

また本システムではリアルタイムに細胞を収集するため，細胞の状態予測や遊離直後の状態推定の対象となる細胞は，最新の離散時刻$\tau$の画像が取得された際にその画像内に写っていた細胞といえる．よってその細胞の集合を$\mathcal{I}_\tau = \left\{1, 2, \dots\right\}$と表すことにする．これを用いると，AIシステムの細胞の状態予測集合$S^{\text{pred}}_{\tau}$および遊離直後の状態推定集合$S^{\text{init}}_{\tau}$は，
\begin{equation}
    \label{eq:cell_state_prediction}
    S^{\text{pred}}_{\tau} = \left\{\hat{\bm{s}}_{\tau + 1}^{(i)} \mid i \in \mathcal{I}_{\tau}\right\},
\end{equation}
\begin{equation}
    \label{eq:cell_initial_state_prediction}
    S^{\text{init}}_{\tau} = \left\{\hat{\bm{s}}_{\tau_{\text{init}}^{(i)}}^{(i)} \mid i \in \mathcal{I}_{\tau}\right\}
\end{equation}
と表される．ただし$\hat{A}$はAIシステムによる$A$の推定値を表し，$\tau_{\text{init}}^{(i)}$は，ある細胞$i$が初めて画像内に写った離散時刻を表している．本論文の以降では，簡便性のため離散時刻$\tau$を$t$で表記することとし，連続的な時刻として$t$を扱う場合には特別に明記することとする．

AIシステムではロボットが細胞の挙動に合わせて効率的にリアルタイムで収集を行うため，これらの出力もリアルタイムで行わなければならない．よって本問題設定では，時刻$t$の画像が得られた際に，それらの画像および時刻$1,2,\dots, t-1$までの画像$\mathcal{X}_1, \mathcal{X}_2, \dots, \mathcal{X}_t$を入力として，その時刻に相当する各予測値$S_t^{\text{pred}}$および各推定値$S_t^{\text{init}}$を出力する，オンライン処理を行うこととする．

\section{関連研究}
\label{sec:related_works}

画像の時系列データを入力として複数の物体の追跡を行うタスクは，一般的に複数物体追跡（Multi Object Tracking,\ MOT）\cite{luo2021multiple}と呼ばれ，町中のカメラに映る歩行者や自動車の追跡など，広く利用されている技術である\cite{milan2016mot16,dendorfer2020mot20}．各画像において物体が存在すればその位置を何かしらの形式で認識し，各物体が他の時刻ではどこに存在するのかを特定することで，追跡対象の行く先から細胞内を動く微粒子の特性まで，様々な情報を得ることができる．

中でもTracking-by-Detectionというフレームワークは，画像を一枚ごとに検出器にかけたのちにデータの対応付けを行うという問題に落とし込んでおり，非常に単純かつ強力な手法として知られている．もっともシンプルなTracking-by-Detectionの手法は，カルマンフィルタによる位置予測とハンガリー法を用いた検出対応付けである．また最近の研究では，重なり合いによる検出抜けに対処するために，CNN\cite{Goodfellow2016,lecun1998gradient}などによる外観情報を対応付けのスコアに含める手法\cite{wojke2017simple,du2023strongsort}や，重なり合いによって切られた軌跡同士を事後的につなぎ合わせる手法\cite{zhang2022bytetrack}などが開発されている．

MOT問題の多くは，二次元画像を入力とした2D-MOTがほとんどである．2D-MOTではバウンディングボックスと呼ばれる矩形もしくはセグメンテーションと呼ばれる2次元点群で検出が行われる．一方で近年，三次元空間を対象とした3D-MOT手法も開発が進んでいる．3D-MOTでは，LiDARなどによる三次元点群で検出が行われ，これに準じたカルマンフィルタの状態空間モデル構築を利用する手法が一般的である\cite{wang2023camo,wang2022deepfusionmot}．

一方共焦点顕微鏡は三次元空間を複数の二次元画像として捉え，またそこには時間的なラグが生じるため，これらの手法をそのまま本問題に適用することは，精度の低下に繋がりかねない．実際に三次元的なタイムラプス顕微鏡から得られたデータに対応するためには，複雑な計算やコストを要し，そこには何かしらの工夫が必要である．例えば\cite{5676210}では，状態空間モデルとして三次元可変メッシュを用いている．また\cite{smal2008particle}では，微小管を対象として光退色効果や物体相互作用を考慮した状態空間モデルの設計を行っている．他にも\cite{1621229}では蛍光顕微鏡から得られたスポット状粒子を追跡するために，画像のウェーブレット変換を行って各光粒子の観測系列を得ている．

そこで本研究では，共焦点顕微鏡から得られる複数の二次元画像入力に対し，2D-MOTで用いられるバウンディングボックス形式の検出を適用し，自然な形で拡張を行うことにより三次元空間における追跡手法を開発する．またカルマンフィルタの再設計により，非常に単純な形で，三次元空間における細胞の状態変数と二次元画像から得られるバウンディングボックスの観測変数を状態空間モデルに落とし込む．