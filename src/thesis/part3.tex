\thispagestyle{fancy2}

本章では，まず既存の要素技術として，Tracking-by-Detectionのフレームワークおよび有名な構成要素である，物体検出手法のYOLO，対応付け手法のSORTについて詳細に述べる（\ref{sec:existing_method}節）．そしてそれらをもとに，複数の二次元画像入力に対応した提案手法の説明を行う（\ref{sec:proposed_method}節）．提案部分としては，三次元的な状態推定を可能にするSliceKalmanFilter（\ref{subsec:sliced_kalman_filter}項）と，スライスを跨いだ対応付けを可能にするDepthSORT（\ref{subsec:reidentificataion_for_slice}項）の説明を述べる．

\section{Tracking-by-Detectionの既存手法と適用上の問題点}
\label{sec:existing_method}

Tracking-by-Detectionでは，毎時刻に得られるデータをそのたびに検出器に入力し，そのデータ内に存在する各物体の情報を得る．そして続く追跡では，新しく得られた各物体の情報に対して，今までに得られたどの物体と同じ物体であるのか，もしくは今までにない新しい物体なのかを判断する対応付けを行う．

YOLO（You Only Look Once）\cite{redmon2016you,alif2024yolov1}は，検出を高速で行うことができるニューラルネットワークである．物体追跡ではリアルタイム性が重視されるため，特にYOLOはTracking-by-Detectionの検出器として利用される．またSORT（Simple Onle Realtime Tracking）\cite{bewley2016simple,wojke2017simple,du2023strongsort}は，IDを割り振ることで追跡を達成する最も単純な手法であり，対応付け手法の基盤として優れている．このSORTは，連続する二時刻のフレーム間で対応付けを最適化するハンガリー法\cite{kuhn1955hungarian}と，対応付けに予測位置を利用するためのカルマンフィルタ\cite{bishop2001introduction}で構成されている．

よって以降の節では，YOLOとSORTを組み合わせたTracking-by-Detectionの全体の概要を述べた後（\ref{subsec:yolo_and_sort}項），物体検出手法のYOLO（\ref{subsec:object_detection}項）と追跡手法のSORTの概要（\ref{subsec:abstract_of_sort}項）を述べる．またSORTを構成するハンガリー法による割当問題（\ref{subsec:hungarian_algorithm}項）とカルマンフィルタ（\ref{subsec:kalman_filter}項）について述べる．これらの要素技術は後述の提案手法（\ref{sec:proposed_method}節）でも利用されるため，詳細に説明を述べている．そしてそのあとにSORTのアルゴリズムを詳細に述べる（\ref{subsec:sort_algorithm}項）．また最後には，この既存手法を本問題設定に適用するうえで生じる問題について議論する（\ref{subsec:existing_problem}項）．

    \subsection{YOLOとSORTによるTracking-by-Detection}
    \label{subsec:yolo_and_sort}
    
    全体のアルゴリズムを説明する前に，まずはYOLOを用いて達成される物体検出というタスクとSORTを用いて達成されるReIDというタスクについて，それぞれの入力や出力を述べる．

        \subsubsection{物体検出}
        物体検出とは，コンピュータビジョンタスクおよび技術の一つであり，一枚の画像を入力した際に，物体の位置を検出し，その物体が何であるかを特定するタスクのことである．物体の位置はバウンディングボックスと呼ばれる矩形領域で表され，一方物体が何であるかは，事前に設定したクラス候補に対するクラス分類で行われる．また，画像内に複数の物体が存在する場合に，それらを同時かつ個別に位置特定およびクラス分類を行うことができる．

        物体の位置を示すバウンディングボックス$\bm{b}$は，画像上のピクセル位置$(x, y)$と画像における物体の幅と高さ$(w,h)$を用いて，
        \begin{equation}
            \label{eq:bounding_box}
            \bm{b} = \left[x, y, w, h\right]^{\top}
        \end{equation}
        で表される．また一つの検出されたバウンディングボックスについて，その所属するクラスは，事前に候補とした各クラスに対する$[0, 1]$の確率で表現される．すなわち出力されるクラス確率$\bm{c}$は，用意したクラス候補集合$\mathcal{C}$を$\left\{c_i \mid i \in \mathcal{C}\right\}$として，
        \begin{equation}
            \label{eq:class_probability}
            \bm{c} = \left\{p(c_i) \mid i \in \mathcal{C}\right\}
        \end{equation}
        で表される．

        これらを用いて，物体検出器$f$がある画像$X \in \mathbb{R}^{W \times H \times 3}$を入力した時に得られる出力$Y$は，
        \begin{equation}
            \label{eq:object_detection}
            \begin{aligned}
                f(X) &= Y
                \\ &= \left\{\bm{b}^{(j)}, ~\bm{c}^{(j)} \mid j \in N_X\right\}
            \end{aligned}
        \end{equation}
        と表される．ここで$N_X$は，ある画像$X$を入力した際に検出された物体数を表している．また$j$はその各物体を表すインデックスである．

        \subsubsection{ReID}
        ReIDとは，検出された各物体の情報（物体検出であればバウンディングボックス）に対して，個体を識別するためのIDを割り当てるタスクである．これにより，同一の個体由来の検出情報の対応付けが達成され，ある物体がどのような軌跡を描いたのか，どこから来たのか，さらにはどのように形状が変化したのかなどの情報を得ることができる．

        ここで，時刻$t$に得られた画像を入力し検出器によって得られた物体の検出情報集合$D_t$を，
        \begin{equation}
            \label{eq:input_to_reid}
            D_t = \left\{\bm{d}^{(i)} \mid i \in N_t\right\}
        \end{equation}
        と表す．ここで$N_t$は時刻$t$の画像を検出器に入力した際に，検出された物体数を表す．また$\bm{d}^{(i)}$は$i$番目の検出情報を表す．例えば検出器に物体検出器を用いれば，$\bm{d}^{(i)}$は式\ref{eq:bounding_box}で表されるバウンディングボックスである．

        ここで時刻$t-1$までに得られた追跡情報のIDの集合を$\mathcal{I}_{t-1} = \left\{1, 2, \dots\right\}$とし，ReIDによって，対応付けされた関係を表すペア$(i, j)$の集合$M = \left\{(i, j)\right\}$が得られたとする（$i$は$\mathcal{I}_{t-1}$，$j$は$D_t$のインデックスに対応している）．このとき$D_t$および$\mathcal{I}_{t-1}$を入力とするReIDを行う関数を$g(D_t)$とすると，その出力$O_t$は，
        \begin{equation}
            \label{eq:output_of_reid}
            \begin{gathered}
                \begin{aligned}
                    g(D_t, \mathcal{I}_{t-1}) &= O_t
                    \\ &= \left\{\bm{d}_{\text{reid}}^{(i)} \mid i \in \mathcal{I}_t\right\},
                \end{aligned}
                \\ \textbf{where } \bm{d}_{\text{reid}}^{(i)} = \bm{d}^{(j)}, ~ \forall (i, j) \in M \textbf{ or } i \in \mathcal{I}_t \setminus \mathcal{I}_{t-1}
            \end{gathered}
        \end{equation}
        と表される．ここで$\mathcal{I}_t \setminus \mathcal{I}_{t-1}$は，時刻$t$で新たに検出され始めたと認識された物体のID集合を表し，$\bm{d}_{\text{reid}}^{(i)}$は時刻$t$のReIDへの入力$D_t$のうち，IDが$i$の物体に対応付けられたものか，新たに検出され始めたと認識されたものである．

        \subsubsection{物体検出とReIDによるTracking-by-Detection}
        以上の定式化より，物体検出とReIDによるTracking-by-Detectionは，毎時刻$t$における$f(X_t)$と$g(D_t, \mathcal{I}_{t-1})$の繰り返し（アルゴリズム\ref{alg:object_detection_and_reidentification}の2, 7行目）によって実施される．また最初の時刻では，物体検出の結果は全て別個体由来のはずであるため，そのままインデックスをIDとして$O_1$を生成する（アルゴリズム\ref{alg:object_detection_and_reidentification}の5行目）．アルゴリズム\ref{alg:object_detection_and_reidentification}での出力は，各時刻でIDを割り振られた検出情報の集合$O_1, O_2, \dots, O_T$であるが，これらの情報をIDごとに分ければ，各物体がどのような軌跡を通ってきたかを容易に確認することが可能である．

        \begin{algorithm}[t]
            \caption{Object Detection and Re-Identification}
            \label{alg:object_detection_and_reidentification}
            \begin{algorithmic}[1]
                \Require $X_1, X_2, \dots, X_T, ~f, ~g$
                \Ensure $O_1, O_2, \dots, O_T$
                \For {$t = 1 \text{ to } T$}
                    \State $D_t = f(X_t)$
                    \State $ N_t = \left|D_t\right|$
                    \If {$t = 0$}
                        \State $\mathcal{I}_t = \left\{1, 2, \dots, N_t\right\}, ~ O_t = \left\{\bm{d}^{(i)} \mid i \in \mathcal{I}_t\right\}$
                    \Else
                        \State $O_t = g(D_t, \mathcal{I}_{t-1})$
                        \State $\mathcal{I}_t = \left\{i \mid \bm{d}_{\text{reid}}^{(i)} \in O_t\right\}$
                    \EndIf
                \EndFor
                \State \Return $O_1, O_2, \dots, O_T$
            \end{algorithmic}
        \end{algorithm}

    \subsection{リアルタイム物体検出手法：YOLO}
    \label{subsec:object_detection}

    物体検出手法のYOLO（You Only Look Once）\cite{redmon2016you, alif2024yolov1}は，2016年に提案された深層学習モデルである．この手法が開発される以前では，矩形領域抽出とクラス分類の処理は段階的に行われていた\cite{girshick2014rich,girshick2015fast,ren2016faster}ために高速性に欠けていたが，YOLOでは矩形領域抽出とクラス分類をすべてニューラルネットで行うことによりその問題を解決し，リアルタイム物体検出手法として確立した．

    物体検出手法としてしばしば言及される性能は，推論時間と精度のトレードオフである．ここでの推論とは，機械学習モデルを学習させた後に目的のデータを入力して所望の結果を得る操作のことをいう．一般的に深層学習では，モデルの学習パラメータ数を増やせば増やすほど精度が上がる一方，推論時間が大きくなる（図\ref{fig:yolo_tradeoff}）．また逆に推論時間を短くするには，精度の低下を招く．初期モデルのバージョン1（以降v1と表記）以降，この推論時間と精度の向上を図って新たなバージョンが開発され続け，2024年10月時点でv10までアップデートされている．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/yolov10_performance.pdf}
        \caption[YOLOのバージョン比較]{YOLOのバージョン比較．
        （左）推論精度と推論時間のトレードオフを示す．縦軸はCOCOデータセットにおけるAPという評価指標であり，100が最大値である．横軸は一枚の画像の物体検出にかかった時間の平均値を示している．（右）横軸にモデルの学習パラメータ数を取った場合の推論精度とのトレードオフを示す．学習パラメータ数を大きくするほど精度が上がっている．（\cite{wang2024yolov10}より引用）}
        \label{fig:yolo_tradeoff}
    \end{figure}    

        \subsubsection{YOLOの構成要素}
        \label{subsubsec:yolo_components}

        YOLOは式\ref{eq:bounding_box}で表されるバウンディングボックスと式\ref{eq:class_probability}で表されるクラス確率に加え，バウンディングボックスごとに信頼度スコア（Confidence score）と呼ばれる値を出力する．この値は，検出されたバウンディングボックスがどれだけ物体らしいかを表す．またYOLOの出力におけるクラス確率は式\ref{eq:class_probability}の各値$p(c_i)$にこの信頼度スコアを掛けた値になる．一般的に物体検出では，そこに物体があるはずなのに検出ができなかった偽陰性（False Negative,\ FN）と，物体がないはずの場所を検出する偽陽性（False Positive,\ FP）の二種類のエラーが発生する．通常YOLOでは，信頼度スコアの閾値を設けることでこれらのバランスを抑える．例えば，閾値を高くすれば基準が厳しくなるためFPが減り，逆に小さくすれば基準が甘くなるためFNを減らすことができる．また信頼度スコアは後述の非最大抑制にも利用される．

        非最大抑制（Non-Maximum Suppression,\ NMS）は，ある画像内の一つの物体に対して検出結果が二つ以上得られた際に，それらを一つにするための事後アルゴリズムである．NMSでは，前述の信頼度スコアが高い順に，一つのバウンディングボックスに対して重なり具合が一定値以上のバウンディングボックスがあるか確認し，ある場合には信頼度スコアが低い方を削除していく．ここでの重なり具合の評価指標としては後述のIntersection of Union（IoU）が用いられる．ただしNMSは時間的なコストが高く，それに対して改善されたv10ではアルゴリズムに入っていないことに注意されたい．

        \subsubsection{YOLOの学習方法}

        先程も述べたように深層学習では一般的に，モデルの学習パラメータ数を大きくするほど精度が改善される．しかしながらそういったモデルの学習には，より大規模なデータセットを準備しなければならず，学習にも時間がかかる．そういった場合，何かしらのタスクを解くためのモデルを作るたびにゼロからモデルを学習させるのは，データ準備の面でも学習の面でも非常に非効率である．また場合によっては，学習パラメータの初期値によって学習が思ったように進まないこともある．

        そこで深層学習でよく用いられる学習方法が，事前学習（Pre-Training）と微調整（Fine-Tuning）である\cite{radford2018improving}．まず事前学習では，大規模なデータセットで学習を行い汎用的な能力を獲得させ，微調整で本来の目的のタスクおよびデータセットを用いて最終的な学習を行い，そのタスクに特化したモデルを構築する．例えばコンピュータビジョン分野では，データセットの作成が安価である画像分類で事前学習を行い，画像入力に適したモデルを構築する．これにより，大量のデータセットが高価なタスクに適したモデルの構築が可能である．また物体検出やクラス分類では，事前学習時と微調整時でクラスの候補を変えることも可能である．この場合は，最終層だけ新しいものに取り替えればよい（図\ref{fig:PTandFT}）．またこの大規模なデータセットによって事前学習されたモデルおよび学習済みパラメータは，オープンソースで公開されていることが多い．

        \begin{figure}[t]
            \centering    
            \includegraphics[width=\linewidth]{fig/PTandFT.pdf}
            \caption[事前学習（Pre-Training）と微調整（Fine-Tuning）]{事前学習（Pre-Training）と微調整（Fine-Tuning）．この図の例では，微調整時に最終層だけを取り替え（赤色の層），それ以外の層は学習パラメータを固定する例を示している（緑色の層）．}
            \label{fig:PTandFT}
        \end{figure}

    \subsection{SORTの概要}
    \label{subsec:abstract_of_sort}

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/sort.pdf}
        \caption[SORTの処理の概略図]{SORTの処理の概略図．
        時刻$t=4$における例を示している．時刻$t=4$のバウンディングボックスの予測は，それまでの時刻のバウンディングボックスから計算される．対応付けはこれらの予測と物体検出で得られた検出バウンディングボックス間で行われる．また対応付けがあったバウンディングボックスにはそのIDが振られ（赤色と緑色），なかった検出バウンディングボックスには新しい物体として新たなIDが振られる（黄色）．}
        \label{fig:sort}
    \end{figure}

    Tracking-by-DetectionをYOLOによる物体検出とSORTによる追跡によって行う場合，時刻$t$におけるSORTへの入力は，
    \begin{equation}
        \label{eq:input_to_sort}
        B_t = \left\{\bm{b}_t^{(i)} \mid i \in \left\{1 ,2, \dots, N_t\right\}\right\}
    \end{equation}
    で表される．ここで$\bm{b}_t^{(i)}$は式\ref{eq:bounding_box}に時刻を表す添字$t$を加えたバウンディングボックスである．また$N_t$は前項と同様，時刻$t$において検出された物体の個数である．ReIDの目的は，これらのバウンディングボックスに，同一の個体由来のバウンディングボックスには同じIDが振られるように，IDの割り振りを行うことであった．

    SORTではこのIDの割り振りを行うために，連続する二時刻分のバウンディングボックスの対応付けを行う．これにより，時刻$t-1$のあるバウンディングボックスと同じ個体であると認識されたバウンディングボックスには，そのIDが振られる．また同じ個体が時刻$t-1$に見つからない場合は，新しい物体として新しいIDが振られる．これは割当問題として定式化され，後述のハンガリー法によって最適化が行われる．

    しかしながら単純な割当問題を解くだけでは，速度を持った物体や，FPSが低いタスクにうまく適用することができない．この理由については\ref{subsec:sort_algorithm}項で述べる．これに対処するため，SORTではカルマンフィルタによる時刻$t$のバウンディングボックス予測を行い，この予測と実際のバウンディングボックス間で対応付けを行う（図\ref{fig:sort}）．これにより，別個体を同一とみなすミスを防ぎながら対応付けを行うことが可能になる．

    以降では，基本構成要素であるハンガリー法による割当問題最適化とカルマンフィルタについて述べた後， SORTの詳細なアルゴリズムを述べる．

    \subsection{二時刻間の対応付け手法：ハンガリー法による割当問題最適化}
    \label{subsec:hungarian_algorithm}

    \begin{algorithm}[t]
        \caption{Hungarian Matching}
        \label{alg:hungarian_matching}
        \begin{algorithmic}[1]
            \Require $A = \left\{a_1, a_2, \dots, a_n\right\}, B = \left\{b_1, b_2, \dots, b_m\right\}$
            \Ensure $M = \left\{(i, j) \mid Q^*_{ij} = 1 \mid i \leq n , ~ j \leq m\right\}$
            \State $\textbf{Initialize: } \ell = \max(n, m), ~ S = \bm{0}^{\ell \times \ell} \in \mathbb{R}_+^{\ell \times \ell}$
            \For {$i = 1 \text{ to } \ell$}
                \For {$j = 1 \text{ to } \ell$}
                    \If {$ i \leq n , ~ j \leq m$}
                        \State $S_{ij} \gets f_{\text{sim}}(a_i, b_j)$
                    \Else
                        \State $S_{ij} \gets 0$
                    \EndIf
                \EndFor
            \EndFor
            \State $Q^* = hungarian\_algorithm(S)$
            \State \Return $\left\{(i, j) \mid Q^*_{ij} = 1 \mid i \leq n , ~ j \leq m\right\}$
        \end{algorithmic}
    \end{algorithm}

    連続する二時刻分の検出された情報の対応付けは，割当問題として定式化することができる．割当問題とは，複数個のタスクと複数人の作業者を仮定し，作業者によってタスクの進行度が異なる場合に，全体の進行度を最適化するような問題のことである．物体検出の例であれば，タスクをある時刻$t-1$に検出されたバウンディングボックス集合$B_{t-1}$，作業者を時刻$t$に検出されたバウンディングボックス集合$B_{t}$と見立て，進行度をバウンディングボックス同士の距離の$-1$倍などにすれば，対応付けの最適化をすることができる．

    割当問題の定式化を行う．いま$n$人の作業者$a_1, a_2, \dots, a_n$と$n$個のタスク$b_1, b_2, \dots, b_n$があると仮定する．またある作業者$a_i$がタスク$b_j$を行った場合の進行度を表す$s_{ij}$およびすべての組み合わせを並べたスコア行列$S \in \mathbb{R}^{n \times n}$が与えられたとする．また一人の作業者には一つの仕事が割り当てられるとして，どの作業者にどのタスクが割り当てられたのかを示す割当行列$Q \in \left\{0, 1\right\}^{n \times n}$を最適化する対象とする．ここで割当行列の$(i,j)$成分である$q_{ij}$が$0$のとき，作業者$a_i$はタスク$b_j$を行わないことを示し，$1$であれば，タスク$b_j$が作業者$a_i$に割り当てられたことを示す．このとき割当問題は，
    \begin{equation}
        \label{eq:assignment_problem}
        \begin{aligned}
            \text{Minimize }& \sum _{(i, j)} s_{ij} q_{ij}  
            \\ \text{s.t. }& \sum_i q_{ij} = 1,\quad \forall j = 1, 2, \dots, n
            \\ \phantom{\text{s.t.} }& \sum_j q_{ij} = 1,\quad \forall i = 1,2,\dots, n
        \end{aligned}
    \end{equation}
    と表される．ハンガリー法\cite{kuhn1955hungarian}は，このように表される最適化問題を高速に解くことができるアルゴリズムである．

    ここまでは作業者とタスクの数が同一である場合の割当問題を考えてきたが，一般的な問題設定では作業者やタスクに余りがある場合も考えられる．すなわち$n$人の作業者に$m$個のタスクを割り当てる時に，$n \neq m$の場合もあり得る．しかしながらこれを式\ref{eq:assignment_problem}の形で記述し最適化を行うと，$n=m$ならば整数解が得られることが保証される一方，$n\neq m$ではその保証はなくなる (一人に複数のタスクが割り当てられたり，一つのタスクを複数人で行うような解が得られることに相当する)．よって本問題設定のように$n \neq m$になりうる対応付けを行いたい場合は，式\ref{eq:assignment_problem}にさらに，
    \begin{equation}
        \label{eq:intger_assignment_constraint}
        q_{ij} \in \left\{0, 1\right\}, \quad \forall (i,j)
    \end{equation}
    という非連続的な整数条件を加えなければならない．

    しかしこの問題は，新たにダミー作業者もしくはダミータスクを導入すれば，式\ref{eq:intger_assignment_constraint}を与えずに解決することができる．もし作業者が余る$n > m$の場合は$n-m$個のダミータスクを，タスクが余る$m > n$の場合は$m-n$人のダミー作業者を考え，これらに対応する要素が全て$0$のスコア行列をもとのスコア行列$S$に結合する．これにより進行度行列および割当行列は，$\max(n, m)$次の正方行列になり，割当行列の要素は必ず整数になる．さらにスコアの合計を最大化しているため，ダミー作業者およびダミータスクには，スコアの合計を最大化するように余ったタスクおよび作業者が割り当てられ，最適性は担保される．

    以上の議論より，割り当てたいそれぞれの集合の要素数が異なる場合にも，それらの対応付けに割当問題を適用でき，ハンガリー法によってその最適解が得られる．アルゴリズム\ref{alg:hungarian_matching}に，集合$A$と集合$B$が得られた際に各要素の対応付けを行うアルゴリズムを示す．ただしアルゴリズムにおける$Q^*$は最適な場合の割当行列，$f_{\text{sim}}(a_i, b_j)$は要素$a_i$と要素$b_j$の類似度を返す関数を表している．11行目の$hungarian\_algorithm$はハンガリー法による割当問題最適化を行う関数である．また出力は，対応付けられた要素同士のインデックスのペア集合$M$である．

    \subsection{検出位置の予測手法：カルマンフィルタ}
    \label{subsec:kalman_filter}

    SORT\cite{bewley2016simple}の対応付けでは，物体の検出情報の類似度として，後述するIoUが使用される．しかしながらユークリッド距離やコサイン類似度などの評価指標と異なり，IoUはほとんどの場合$0$になる，厳格な評価指標である．そのため対象物体の速度が大きい場合や相対的にFPSが低い場合（特に1フレームで物体の大きさ以上の距離を移動する場合）には，うまく対応付けることができない．

    そこでSORTが利用するのがカルマンフィルタによる予測である．ReIDでは時刻$t$の処理において，それまでのReID結果$O_1, O_2, \dots, O_{t-1}$を得ている（アルゴリズム\ref{alg:object_detection_and_reidentification}）．また前述のように，これをIDごとに分けることによって，各物体の時刻$t-1$までの軌跡を得ることができる．このデータをカルマンフィルタに入力することにより，時刻$t$において追跡をしている各物体の，時刻$t+1$における検出情報の予測を得ることができる．そして時刻$t$の検出情報の代わりに，この予測情報を用いて対応付けを行う．これにより，速度を持った対象に対してもある程度安定した対応付けが可能になる．

        \subsubsection{カルマンフィルタにおける事後確率分布の計算}
        \label{subsubsec:kalmanfilter_setting}

        カルマンフィルタ\cite{bishop2001introduction}とは，センサーなどから得られた時系列データを入力し，システム内部の状態を推定するための最適化アルゴリズムである．ここではセンサーから得られる観測変数の系列を$\bm{o}_1, \bm{o}_2, \dots, \bm{o}_t$，システム内部の状態変数の系列を$\bm{s}_1, \bm{s}_2, \dots, \bm{s}_t$と表記する．カルマンフィルタの目的は，観測系列$\bm{o}_1, \bm{o}_2, \dots, \bm{o}_t$が得られたときに状態変数$\bm{s}_t$の推定値$\hat{\bm{s}}_t$を最適化することである．またここでの最適とは，
        \begin{equation}
            \label{eq:kalman_optimality}
            \hat{\bm{s}}_t^* = \underset{\hat{\bm{s}}_t}{\text{argmin}} ~ \mathbb{E}\left[\left(\hat{\bm{s}}_t - \bm{s}_t\right)^2\right] - \mathbb{E}\left[\hat{\bm{s}}_t - \bm{s}_t\right]^2,
        \end{equation}
        で表される，推定誤差の分散最小化で定義される．ここで$\hat{A}^*$はある変数$A$の最適推定値を表す．

        この分散最小化を行うために，時刻$t$までの観測系列$\bm{o}_1, \bm{o}_2, \dots, \bm{o}_t$を得たときの時刻$t$の状態変数$\bm{s}_t$の事後確率分布を考える．これはベイズの定理より，
        \begin{equation}
            \label{eq:posterior_with_bayes}
            p(\bm{s}_t \mid \bm{o}_1,\dots, \bm{o}_t ) = \frac{p(\bm{o}_t \mid \bm{o}_1,\dots, \bm{o}_{t-1}, \bm{s}_t) p(\bm{s}_t \mid \bm{o}_1,\dots, \bm{o}_{t-1})}{p(\bm{o}_t \mid \bm{o}_1,\dots, \bm{o}_{t-1})}
        \end{equation}
        と書き下せる．また右辺の分子後半部$p(\bm{s}_t \mid \bm{o}_1,\dots, \bm{o}_{t-1})$は条件付き確率の性質から，
        \begin{equation}
            \label{eq:posterior_with_conditioning}
            p(\bm{s}_t \mid \bm{o}_1,\dots, \bm{o}_{t-1}) = \int p(\bm{s}_t \mid \bm{s}_{t-1}, \bm{o}_1, \dots, \bm{o}_{t-1}) ~ p(\bm{s}_{t-1} \mid \bm{o}_1, \dots, \bm{o}_{t-1}) d\bm{s}_{t-1}
        \end{equation}
        で計算できる．

        式\ref{eq:posterior_with_bayes}と式\ref{eq:posterior_with_conditioning}より，$p(\bm{s}_0 \mid \bm{o}_0) = p(\bm{s}_0)$が与えられればすべての時刻$t = 1, 2, \dots, t$における事後確率分布が理論上には計算することができる．しかしながら式\ref{eq:posterior_with_bayes}における分母や式\ref{eq:posterior_with_conditioning}における右辺には積分が含まれるため，現実には計算することができない．

        そのため一般的なカルマンフィルタでは，システムや観測の線形性とマルコフ性，およびノイズの正規性を仮定する．すなわち，
        \begin{equation}
            \label{eq:kalman_GL}
            \begin{aligned}
                \bm{s}_{t+1} &= F_t \bm{s}_t + \bm{v}_t, \quad \bm{v}_t \sim \mathcal{N}(\bm{0}, Q_t),
                \\ \bm{o}_t &= H_t \bm{s}_t + \bm{w}_t, \quad \bm{w}_t \sim \mathcal{N}(\bm{0}, R_t)
            \end{aligned}        
        \end{equation}
        を仮定する．上の式は状態遷移式，下の式は観測方程式と呼ばれる．ここで$F_t$は時刻$t$における状態変数の時間遷移を表す遷移行列，$H_t$は時刻$t$における状態から観測への変換を表す観測行列である．また$\bm{v}_t$はシステムに加えられるノイズ，$\bm{w}_t$は観測時に観測変数に加えられるノイズである．

        以上の仮定により，時刻$t+1$の状態変数は時刻$t$の状態変数のみによって記述でき，また時刻$t$の観測変数も同様に時刻$t$の状態変数のみによって記述できる．すなわち，
        \begin{equation}
            \label{eq:kalman_with_markov}
            \begin{aligned}
                p(\bm{s}_{t} \mid \bm{s}_{t-1}, \bm{o}_1, \dots, \bm{o}_t) &= p(\bm{s}_t \mid \bm{s}_t),
                \\p(\bm{o}_t \mid \bm{o}_1, \dots, \bm{o}_{t-1}, \bm{s}_t) &= p(\bm{o}_t \mid \bm{s}_t)
            \end{aligned}
        \end{equation}
        が成り立つ．さらにこれらは式\ref{eq:kalman_GL}の各変数を用いると，
        \begin{equation}
            \label{eq:linear_transition_and_observation}
            \begin{aligned}
                p(\bm{s}_t \mid \bm{s}_{t-1}) &= \mathcal{N}(F_{t-1} \bm{s}_{t-1}, Q_{t-1}),
                \\ p(\bm{o}_t \mid \bm{s}_t) &= \mathcal{N}(H_t \bm{s}_{t}, R_t)
            \end{aligned}
        \end{equation}
        のように正規分布の形で記述できる．

        ここでカルマンフィルタの枠組みでは，時刻$0$における状態変数の事前分布$p(\bm{s}_0)$が正規性を持ち，$p(\bm{s}_0) = \mathcal{N}(\bm{\mu}_{0 \mid 0}, \Sigma_{0 \mid 0})$と表されると仮定する．すると式\ref{eq:posterior_with_bayes}および\ref{eq:posterior_with_conditioning}はすべて正規分布同士の積で表すことができ，その結果もまた正規分布になることが保証される．よって，
        \begin{equation}
            \label{eq:normal_dist_representation}
            \begin{aligned}
                p(\bm{s}_t \mid \bm{o}1, \dots, \bm{o}_t)& = \mathcal{N}\left(\bm{\mu}_{t \mid t}, \Sigma_{t \mid t}\right),
                \\ p(\bm{s}_{t+1} \mid \bm{o}1, \dots, \bm{o}_t) &= \mathcal{N}\left(\bm{\mu}_{t+1 \mid t}, \Sigma_{t+1 \mid t}\right)
            \end{aligned}
        \end{equation}
        と表すと，これら平均と分散は式\ref{eq:kalman_GL}中の変数を用いて，
        \begin{equation}
            \label{eq:estimation_equations}
            \begin{aligned}
                \bm{\mu}_{t \mid t-1} &= F_{t-1} \bm{\mu}_{t-1 \mid t-1},
                \\\Sigma_{t \mid t-1} &= F_{t-1} \Sigma_{t-1 \mid t-1} F_{t-1}^{\top} + Q_{t-1},
                \\\bm{\mu}_{t \mid t} &= \Sigma_{t \mid t} \left( H_t R_t^{-1} \bm{o}_t + \Sigma_{t \mid t-1}^{-1} \bm{\mu}_{t \mid t-1} \right),
                \\\Sigma_{t \mid t} &= \left( H_t R_t^{-1} H_t^{\top} + \Sigma_{t \mid t-1}^{-1}\right)^{-1}
            \end{aligned}
        \end{equation}
        と表され，計算可能になる．ただしここで$\bm{\mu}_{0 \mid 0}$および$\Sigma_{0 \mid 0}$はハイパーパラメータである．また一般的にはカルマンゲイン
        \begin{equation}
            \label{eq:kalman_gain}
            K_t = \Sigma_{t \mid t-1} H_t^{\top} \left(H_t \Sigma_{t \mid t-1} H_t^{\top} + R_t\right)^{-1}
        \end{equation}
        を用いて，
        \begin{equation}
            \label{eq:estimation_equations_with_K}
            \begin{aligned}
                \bm{\mu}_{t \mid t-1} &= F_{t-1} \bm{\mu}_{t-1 \mid t-1},
                \\\Sigma_{t \mid t-1} &= F_{t-1} \Sigma_{t-1 \mid t-1} F_{t-1}^{\top} + Q_{t-1},
                \\\bm{\mu}_{t \mid t} &= \bm{\mu}_{t \mid t-1} + K_t \left(\bm{o}_t - H_t \bm{\mu}_{t \mid t-1}\right),
                \\\Sigma_{t \mid t} &= (I - K_t H_t) \Sigma_{t \mid t-1}
            \end{aligned}                    
        \end{equation}
        と表される．

        また$\bm{s}_t$が正規分布に従うとき，式\ref{eq:kalman_optimality}を満たす推定値は正規分布の平均値になる．以上より観測系列$\bm{o}_1, \dots, \bm{o}_t$が得られたときの状態変数$\bm{s}_t$のカルマンフィルタの最適推定値は，式\ref{eq:estimation_equations_with_K}の$\bm{\mu}_{t \mid t}$で与えられる．

        \subsubsection{カルマンフィルタによる状態推定と観測予測}

        \begin{algorithm}[t]
            \caption[Kalman Estimate]{Kalman Estimate}
            \label{alg:kalman_estimate}
            \begin{algorithmic}[1]
                \Require $O = \left\{\bm{o}_t \mid t \in \mathcal{T} \subset \mathbb{N}_+\right\}, T$
                \Ensure $\hat{\bm{s}}_T$
                \State $\textbf{Initialize: } F, Q, H, R, \Sigma, \bm{\mu} = initial\_estimate(\bm{o}_{\min(\mathcal{T})})$
                \For {$t = \min(\mathcal{T}) + 1 \text{ to } T$}
                    \State $\bm{\mu} \gets F \bm{\mu}$
                    \State $\Sigma \gets F \Sigma F^{\top} + Q$
                    \State $\hat{\bm{s}}_t = \bm{\mu}$
                    \If {$ \bm{o}_t \in O $}
                        \State $K_t = \Sigma H^{\top} \left( H \Sigma H^{\top} + R\right)$
                        \State $\bm{\mu} \gets \bm{\mu} + K_t \left( \bm{o}_t - H \bm{\mu} \right)$
                        \State $\Sigma \gets \left( I - K_t H \right) \Sigma$
                        \State $\hat{\bm{s}}_t \gets \bm{\mu}$
                    \EndIf
                \EndFor
                \State \Return $\hat{\bm{s}}_T$
            \end{algorithmic}
        \end{algorithm}

        \begin{algorithm}[t]
            \caption[Kalman Predict]{Kalman Predict}
            \label{alg:kalman_predict}
            \begin{algorithmic}[1]
                \Require $O = \left\{\bm{o}_t \mid t \in \mathcal{T} \subset \mathbb{N}_+\right\}, T$
                \Ensure $\hat{\bm{o}}_T$
                \State $\hat{\bm{s}}_T = kalman\_estimate(O, T)$
                \State $\hat{\bm{o}}_T = H \hat{\bm{s}}_T$
                \State \Return $\hat{\bm{o}}_T$
            \end{algorithmic}
        \end{algorithm}


        式\ref{eq:estimation_equations_with_K}を用いて，時刻$T$までの観測系列を入力として状態変数$\bm{s}_T$の推定を行う処理をアルゴリズム\ref{alg:kalman_estimate}に示す．ただしここでは簡易化のため，状態遷移式および観測方程式における各変数は定常なものであるとした．また式\ref{eq:estimation_equations_with_K}で表される平均と分散は更新する形で記述した．
        
        初期推定値$\bm{\mu}$は，入力された観測系列に含まれる初期時刻の観測変数を入力された$initial\_estimate$関数によって得ることとした．この関数は後述の\ref{subsec:sort_algorithm}や\ref{subsec:sliced_kalman_filter}で具体的な処理を述べる．またこれらの後述のために，観測系列に抜け落ちがある場合でも適用できるように記述した（入力における$\mathcal{T}$およびアルゴリズム6行目）．

        またカルマンフィルタでは，時刻$t$までの観測系列が得られたときに，時刻$t+1$の状態予測だけではなく観測変数の予測も行うことができる．これを行うためには，前述の$kalman\_estimate$関数から得られた$\hat{\bm{s}}_T$を観測方程式（式\ref{eq:kalman_GL}）の$\bm{s}_t$に代入し，期待値をとればよい．このアルゴリズムをアルゴリズム\ref{alg:kalman_predict}に示す．システムが線形の場合は状態推定値に観測行列$H$をかけるだけでこの観測予測値が得られる．

    \subsection{SORTのアルゴリズム}
    \label{subsec:sort_algorithm}

    \begin{algorithm}[t]
        \caption[SORT]{SORT}
        \label{alg:sort}
        \begin{algorithmic}[1]
            \Require $\mathcal{B} = \left\{B_t = \left\{\bm{b}_t^{(1)}, \bm{b}_t^{(2)}, \dots\right\} \mid t \in \left\{1, 2, \dots, T\right\}\right\}$
            \Ensure $\mathcal{O}_T = \left\{O^{(i)} \mid i \in \mathcal{I}_T\right\}$
            \State $\textbf{Initialize: } \mathcal{O}_{1} = \emptyset,\ \sigma_{\text{act}}$
            \For {$\bm{b}_j \text{ in } B_1$}
                \State $\text{add } O^{(j)} = \left\{\bm{b}_1^{(j)}\right\} \text{ to } \mathcal{O}_{1}$
                \State $\text{add } j \text{ to }\mathcal{I}_1 $
            \EndFor
            \For {$t = 2 \text{ to } T$}
                \State $\hat{B}_t = \emptyset,\ \mathcal{O}_t = \emptyset$
                \For {$O^{(i)} \text{ in } \mathcal{O}_{t-1}$}
                    \State $\hat{\bm{b}}_t^{(i)} = kalman\_predict(O^{(i)}, t)$
                    \State $\text{add } \hat{\bm{b}}_t^{(i)} \text{ to }\hat{B}_t $
                \EndFor
                \State $M_t = hungarian\_matching(\hat{B}_t, B_t)$
                \For {$(i,j) \text{ in } M_t$}
                    \State $\text{add } \bm{b}_t^{(j)} \text{ to } O^{(i)}$
                    \State $\text{add } O^{(i)} \text{ to } \mathcal{O}_t$
                    \State $\text{add } i \text{ to } \mathcal{I}_t$
                \EndFor
                % \For {$j \text{ in } N_t$}
                %     \State $i_n = \max (\mathcal{I}_1 \cup \mathcal{I}_2 \cup \cdots \cup \mathcal{I}_{t-1}) + 1$
                %     \State $\text{add } O_{i_n} = \left\{\bm{b}_t^{(j)}\right\} \text{ to } \mathcal{O}_{t}$
                %     \State $\text{add } i_n \text{ to } \mathcal{I}_t$
                % \EndFor
                \For {$i \text{ in } \mathcal{I}_{t-1}$}
                    \State $\sigma_i = calculate\_staleness(i, \mathcal{I}_1, \mathcal{I}_2, \dots, \mathcal{I}_t)$
                    \If {$\sigma_i \leq \sigma_{\text{act}}$}
                        \State $\text{add } O^{(i)} \text{ to } \mathcal{O}_t$
                    \EndIf
                \EndFor
            \EndFor
            \State \Return $\mathcal{O}_{T}$
        \end{algorithmic}
    \end{algorithm}

    割当問題によって連続する二時刻のバウンディングボックス間対応付けを行う場合，直感的には類似度にバウンディングボックス同士の距離の$-1$倍や逆数を用いるのが自然である．しかしながら連続する二時刻のバウンディングボックス間で，お互いに対応づかない別個体があるときには，別個体由来の対応付けが行われる可能性がある．なぜならばどれだけ距離が大きい場合でも，ダミーに対応付けられるよりは全体のスコアを上げるためである．またそういった対応付けを防ぐためにダミーに対するスコアを$0$より大きくするという対処法も考えられるが，この場合は正しい対応付けも排除する可能性があり，値の微調整が必要になる．

    \begin{figure}[t]
        \centering
        \includegraphics[width=.6\linewidth]{fig/intersection_of_union.pdf}
        \caption[バウンディングボックスにおけるIoU]{バウンディングボックスにおけるIoU．和領域の面積に対する積領域の面積の大きさがIoUとなる．}
        \label{fig:intersection_of_union}
    \end{figure}

    そこでSORTでは，類似度にIntersection of Union（以後IoUと表記）を用いる．ある二つのバウンディングボックス$\bm{b}_1, \bm{b}_2$のIoUは，図\ref{fig:intersection_of_union}に示すように，二つのバウンディングボックスの和領域に対する積領域の割合として計算される．SORTでは$f_{\text{sim}}(\bm{b}_1, \bm{b}_2) = \text{IoU}(\bm{b}_1, \bm{b}_2)$として二時刻間の対応付けを行う．IoUは重なりあう領域がまったくない場合に$0$になるため，非常に対応付けに保守的であり，間違った対応付けをしなくて済む．そして保守的になった分対応づきにくくなる問題に対しては，カルマンフィルタによるバウンディングボックスの予測によって解決する．もし仮に物体がフレームレートに対して大きい速度を持っている場合には，IoUは限りなく0になりやすくなる．しかし速度や加速度を知っていれば時刻$t$のバウンディングボックスの位置を予測でき，速度などによらずIoUを高めることができる．よって速度や加速度を含んだ状態変数のカルマンフィルタを設計し，バウンディングボックスの予測を行う．

    バウンディングボックスに対応する状態変数を，位置，大きさ，そして位置の一階微分である速度で表す．すなわち時刻$t$における状態変数$\bm{s}_t$は，
    \begin{equation}
        \label{eq:sort_state_vector}
        \bm{s}_t = \left[x, \dot{x}, y, \dot{y}, w, h\right]^{\top}
    \end{equation}
    で表される．このとき遷移行列$F_t$は，線形関係式
    \begin{equation}
        \label{eq:sort_transition}
        \begin{aligned}
            x_{t+1} &= x_t + \dot{x}_t dt + \frac{1}{2} a_t dt^2
            \\\dot{x}_{t+1} &= \dot{x}_t + a_t dt
            \\a_t &\sim \mathcal{N}(0, A_x)
        \end{aligned}
    \end{equation}
    を満たすように設計される．ここで$dt$は，離散的な時刻間に相当する連続時間長さである．また$a_t$は正規性をもつノイズであり，システムに対して加速度として加算される．$A_x$はその分散を表す．ここでは冗長性のため$x$のみに対する関係を記述したが，$y$についても同様の関係が成り立つ．また観測行列$H_t$は，状態変数の$0$階微分成分をそのまま利用するように設計される．

    SORTの処理をアルゴリズム\ref{alg:sort}に示す．ただしここでの出力はIDごとの観測系列になっていることに注意されたい．アルゴリズム\ref{alg:object_detection_and_reidentification}でも示したように，Tracking-by-Detectionでは時刻$t$のReIDにおいて，時刻$t-1$までのReID結果$O_1, O_2, \dots, O_{t-1}$を得ている．これをIDごとに分ければ，各個体の軌跡，言い換えれば観測系列を得ることができる．これを用いてSORTは，時刻$t$のバウンディングボックス集合$B_t$を得たときに，はじめに$B_t$の予測を行う（8-9行目）．そしてその予測バウンディングボックスと実際に検出されたバウンディングボックス集合とで，割当問題およびハンガリー法による対応付けを行う（12行目）．そして対応付けられたバウンディングボックスを軌跡$O^{(i)}$に加える（14-16行目）．ここまでがSORTの基本的な時刻$t$における処理である．
    
    また明瞭さのため省略したが，実際には対応づかなかった検出バウンディングボックスを新しいIDの個体とし，軌跡に加えるという処理も行う．このときのバウンディングボックスを$[x,y,w,h]$とすると，この時刻以降のカルマンフィルタの観測予測は，事後分布の初期期待値を
    \begin{equation}
        \label{eq:SORT_kalman_initialize}
        \begin{aligned}
            \bm{\mu} = \left[x, 0, y, 0, w, h\right]^{\top}
        \end{aligned}
    \end{equation}
    として計算される．この計算はアルゴリズム\ref{alg:kalman_estimate}の初期化における$initial\_estimate$関数に相当している．

    また18-19行目では，時刻$t-1$で追跡している各物体に対して，何時刻分の間対応付けがされなかったのかを$calculate\_staleness$関数によって計算している．そしてこの値がある閾値$\sigma_{\text{act}}$より大きいものは追跡を止める．この閾値は，検出の精度に応じて調整することが望まれる．例えば検出の見逃し（FN）が多い場合には，この値を大きくして追跡の打ち切りを緩和したほうがよい．ただし大きくしすぎると別個体由来の検出と対応付く可能性が高くなるため，注意が必要である．

    \subsection{既存手法の問題点}
    \label{subsec:existing_problem}

    本問題設定と一般的なMOTおよびTracking-by-Detectionが対象にしている問題設定とで大きく異なる点は，対象空間が三次元空間であり，各時刻で入力される画像が一枚ではなく$n_s$枚あることである．これによって生じる問題点の一つ目は，追跡によってわれわれが得たい情報が異なることである．アルゴリズム\ref{alg:object_detection_and_reidentification}やアルゴリズム\ref{alg:sort}に見られたようにTracking-by-Detectionでは，ある時刻に検出された物体が，他の時刻ではどの検出された物体なのか，ということに焦点を当ており，カルマンフィルタは対応付けのための補助的な役割を果たしていた．

    しかしながらわれわれの問題設定では，むしろカルマンフィルタの出力に興味がある．なぜならば最終的に得たい情報は式\ref{eq:discreted_state_vector}や式\ref{eq:cell_state_prediction}で表されるような三次元情報であり，これらを求めるにはカルマンフィルタなどによる推定が必要であるためである．よって本問題設定に適用するには，カルマンフィルタの状態変数や各種行列などの再設計が必要である．

    そして二つ目の問題が，その再設計されるカルマンフィルタの観測系列をどのように得るか，という問題である．三次元的な状態の推定を行うのであれば，観測系列にも三次元的な情報を含めるのが自然である．また既存手法を用いて図\ref{fig:existing_problem}（左）のように二次元的な観測系列を得ることは可能であるが，これらのみで三次元的な状態推定を高精度に行えるかどうかは非自明である．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/existing_problem.pdf}
        \caption[既存手法の問題点]{既存手法の問題点．黒色の平面が各画像，赤色の矩形が検出されたバウンディングボックスを表す．また重ねられた画像は，スライスの高さが異なっている．右の図におけるバウンディングボックスは，すべて同一の個体由来のバウンディングボックスを示している．}
        \label{fig:existing_problem}
    \end{figure}

    そこで次節で説明する提案手法では，まず問題点の一つ目である三次元的な状態推定のためのカルマンフィルタの設計を行う．この設計では，物体検出から得られるバウンディングボックスの集合を観測変数，推定したい変数を状態変数とした非常に直感的な状態空間モデルを使用する．そして問題点の二つ目である三次元的な観測変数の獲得方法として，DepthSORTというアルゴリズムを組み合わせたReID手法を提案する．このDepthSORTのアルゴリズム自体は既存手法の一部であるSORTと同様であり，発想自体も非常に単純である．このReID手法によって，図\ref{fig:existing_problem}（右）に示すような，一時刻に複数のバウンディングボックスを持った，三次元的な観測変数の取得を可能にする．

\section{新しいカルマンフィルタの設計および複数スライスに対応したReID手法}
\label{sec:proposed_method}

本章では，はじめに提案手法の概要を述べた後（\ref{subsec:proposed_pipeline}節），提案部分であるSliceKalmanFilter（\ref{subsec:sliced_kalman_filter}節）およびDepthSORTを利用したReIDについて詳細に述べる（\ref{subsec:reidentificataion_for_slice}節）．

    \subsection{提案手法のパイプライン概要}
    \label{subsec:proposed_pipeline}

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/proposed_pipeline.pdf}
        \caption[提案手法を組み込んだパイプライン概要]{提案手法を組み込んだパイプライン概要．毎時刻に各スライスの二次元画像が入力され，まずはじめに物体検出に掛けられる．これにより得られたバウンディングボックスと，その時刻までの各物体の状態推定値から予測したバウンディングボックスにより，スライスを跨いだ三次元的なReIDを実施する．そして最後に，このスライスを跨いだバウンディングボックス集合を観測変数として状態推定値を更新する．}
        \label{fig:proposed_pipeline}
    \end{figure}

    提案手法では，既存手法と同様Tracking-by-Detectionの枠組みに則り，物体検出手法に関しては既存手法と同様YOLOを使用する．すなわち，複数の二次元画像入力$\mathcal{X}_t = \left\{X_{t, s} \mid s \in {1, \dots, n_s}\right\}$をそれぞれ独立にYOLOに入力し，それぞれのバウンディングボックス集合$B_{t,s} = \left\{\bm{b}_{t,s}^{(j)}\right\}$を得る（図\ref{fig:proposed_pipeline}の(1) Object Detection）．添字の$(t,s)$は，時刻$t$における$s$番目のスライスを表している．

    続くReIDでは既存手法と異なり，複数のスライスに対応した$B_{t,1}, B_{t,2}, \dots, B_{t,n_s}$が入力となる．出力としては既存手法のReIDおよびSORTと同様に，各集合に含まれるすべてのバウンディングボックス$\bm{b}$にIDを与えたものが得られる（図\ref{fig:proposed_pipeline}の(2) Re-Identification）．提案手法ではDepthSORTという高さ方向のSORTを実施することで，同時刻のスライス間で対応付けを行う．これにより，後続のカルマンフィルタに三次元的な観測変数を渡すことができる．

    新たに設計を行うカルマンフィルタでは，異なるスライスに対応した複数のバウンディングボックスを観測変数として，三次元的な状態の推定を行う（図\ref{fig:proposed_pipeline}の(3) State Estimation）．このカルマンフィルタをSliceKalmanFilterと呼ぶこととする．この設計では，非線形な写像に対応するための拡張カルマンフィルタと，新たに提案する可変的な観測変数を利用する．

    最後に，\ref{sec:setting_fomulization}節で説明した出力（式\ref{eq:cell_state_prediction}および式\ref{eq:cell_initial_state_prediction}）を得る方法について説明する．まず式\ref{eq:cell_state_prediction}で表される時刻$t+1$の予測は，カルマンフィルタの状態推定における状態予測値（アルゴリズム\ref{alg:kalman_estimate}の3行目）によって得られる．ただしここで用いられるカルマンフィルタは，三次元的な状態変数を持つSliceKalmanFilterである．また式\ref{eq:cell_initial_state_prediction}で表される初期時刻の状態推定値には，単純に各物体が追跡され始めた時刻$t_{\text{init}}$における状態推定値$\hat{\bm{s}}_{t_{\text{init}}}$を用いる．

    \subsection{複数スライスに対応したカルマンフィルタ}
    \label{subsec:sliced_kalman_filter}
    
    既存手法におけるカルマンフィルタの役割は，対応付けに用いるバウンディングボックスを予測することであった．しかしながら本問題設定では，観測系列から直接得ることができない三次元情報を推定しなければならない．そこでわれわれは対応付け用のカルマンフィルタとは別に，SliceKalmanFilterと呼ばれる新たな状態推定用のカルマンフィルタを構築する．
    
    まずは状態変数を所望の三次元情報として設計する．すなわち式\ref{eq:discreted_state_vector}を参考にして，
    \begin{equation}
        \label{eq:skf_state_vector}
        \bm{s}_t = \left[x_t, \dot{x}_t, y_t, \dot{y}_t, z_t, \dot{z}_t, r_t\right]^{\top}
    \end{equation}
    を状態変数とする．このとき状態遷移式は一般的なカルマンフィルタの状態遷移式\ref{eq:kalman_GL}と同様に，
    \begin{equation}
        \label{eq:skf_state_transition}
        \bm{s}_{t+1} = F_t \bm{s}_t + \bm{v}_t, \quad \bm{v}_t \sim \mathcal{N}(\bm{0}, Q_t)
    \end{equation}
    で表され，遷移行列$F_t$は位置$(x,y,z)$に対して式\ref{eq:sort_transition}を満たすように設計される．また半径$r_t$は定常であると仮定する．またSliceKalmanFilterにおける$dt$は，フレーム間隔である$\delta t$であることに注意されたい．

    次に観測変数について設計を行うが，ここではまず単一のスライス$s$のみを考慮した観測変数$\bm{o}_{t, s}$を考える．この観測変数は当然ながら一つのバウンディングボックスを表すため，
    \begin{equation}
        \label{eq:single_slice_observation}
        \bm{o}_{t, s} = \left[x_s, y_s, w_s, h_s\right]^{\top}
    \end{equation}
    と表される．ここで\ref{sec:setting_fomulization}節および式\ref{eq:appearant_radius}，\ref{eq:circle_region}で説明をした共焦点顕微鏡から得られる二次元画像の特性を考慮すると，状態変数$\bm{s}_t$を入力して同時刻のスライス$s$に対する観測変数$\bm{o}_{t,s}$を返す関数$h_s(\cdot)$は，
    \begin{equation}
        \label{eq:single_slice_observation_map}
        \begin{gathered}
            \begin{aligned}
                h_s(\left[x_t, \dot{x}_t, y_t, \dot{y}_t, z_t, \dot{z}_t, r_t\right]) &= \left[x_s, y_s, w_s, h_s\right]^{\top}
                \\ &= 
                \begin{bmatrix}
                    x_t + \dot{x}_t (s - 1) t_c
                    \\ y_t + \dot{y}_t (s - 1) t_c
                    \\ 2r_t^{\text{app}}
                    \\ 2r_t^{\text{app}}
                \end{bmatrix},                
            \end{aligned}
            \\ \textbf{where } r_t^{\text{app}} = \sqrt{r_t^2 - \left\{(s - 1)\delta z - \left(z_t + \dot{z}_t (s - 1) t_c\right) \right\}^2}
        \end{gathered}
    \end{equation}
    で表される．ただし$t_c, \delta z$は\ref{sec:setting_fomulization}節で説明した，それぞれ共焦点顕微鏡から一枚の二次元画像を得るのに要する時間と各スライスの間隔の大きさを表している．また$r_t^{\text{app}}$は，スライス$s$に状態変数が$\bm{s}_t$である物体が映る際の見かけの半径を表している（ただしここでは，平面の高さを表す$z$を省略している）．

    この式の注意すべき点は二つある．一つ目は，この観測変数と状態変数の関係が非線形な関係にあることである．式\ref{eq:kalman_GL}で仮定したように，一般的なカルマンフィルタではこの両者の関係に線形性を仮定していたため，何かしらの拡張が必要である．よって提案手法では，拡張カルマンフィルタ\cite{bishop2001introduction}を利用する．また注意すべき二つ目の点は，式\ref{eq:single_slice_observation_map}において，見かけの半径$r_t^{\text{app}}$の右辺の中身が$0$より大きくなければ，そもそも観測変数$\bm{o}_{t,s}$が存在し得ないことである．これについては，拡張カルマンフィルタの説明のあとに詳細を述べる．

        \subsubsection{拡張カルマンフィルタ}
        拡張カルマンフィルタ\cite{bishop2001introduction}は，システムの状態遷移や観測方程式が非線形な式の場合にも対応できる非線形カルマンフィルタの一種である．ここでは提案手法のための説明として，状態変数から観測変数への変換が非線形な関係$h(\cdot)$で結ばれ，観測方程式が，
        \begin{equation}
            \label{eq:ekf_nonlinear}
            \bm{o}_t = h(\bm{s}_t) + \bm{w}_t, \quad \bm{w}_t \sim \mathcal{N}(\bm{0}, R_t)
        \end{equation}
        で表される場合を想定する．

        拡張カルマンフィルタでは，ある状態推定値$\hat{\bm{x}}_t$周りのテーラー展開を行い，非線形な関係$h(\cdot)$の線形化を行う．すなわち非線形関数$h(\bm{s}_t)$を，
        \begin{equation}
            \label{eq:ekf_linearization}
            \begin{aligned}
                h(\bm{s}_t) &\approx h(\hat{\bm{x}}_t) + \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t = \hat{\bm{s}}_t} (\bm{s}_t - \hat{\bm{s}}_t)
                \\ &= \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t = \hat{\bm{s}}_t} \bm{s}_t + h(\hat{\bm{s}}_t) - \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t = \hat{\bm{s}}_t} \hat{\bm{s}}_t
            \end{aligned}
        \end{equation}
        と近似する．ここで仮観測変数
        \begin{equation}
            \label{eq:ekf_new_observation}
            \bm{z}_t = \bm{o}_t - h(\hat{\bm{x}}_t) + \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t = \hat{\bm{s}}_t} \hat{\bm{s}}_t
        \end{equation}
        および仮観測行列
        \begin{equation}
            \label{eq:ekf_new_observation_matrix}
            H_t' = \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t = \hat{\bm{s}}_t}
        \end{equation}
        を新たに定義すると，式\ref{eq:ekf_nonlinear}は，
        \begin{equation}
            \label{eq:ekf_linearization_with_z}
            \bm{z}_t = H'_t \bm{s}_t + \bm{w}_t, \quad \bm{w}_t \sim \mathcal{N}(\bm{0}, R_t) 
        \end{equation}
        と表現できる．

        式\ref{eq:ekf_new_observation}に着目すると，仮観測変数$\bm{z}_t$は元々の観測変数$\bm{o}_t$と既知関数$h(\cdot)$とある状態推定値$\hat{\bm{s}}_t$から計算される．拡張カルマンフィルタでは，この状態推定値に式\ref{eq:estimation_equations}における状態予測値$\bm{\mu}_{t\mid t-1}$を用いるため，仮観測変数$\bm{z}_t$は観測変数$\bm{o}_t$と同タイミングで得ることができる．また仮観測行列$H'_t$も同タイミングで計算可能である．

        以上の議論より拡張カルマンフィルタは，仮観測変数$\bm{z}_t$を観測変数，仮観測行列$H'_t$を観測行列としてカルマンフィルタの最適化アルゴリズムを実行することで，非線形なシステムに対応することができる．よって通常のカルマンフィルタと同様に状態推定（アルゴリズム\ref{alg:kalman_estimate}）が使用できる（ただしこの場合，観測行列は毎時刻で計算する必要がある）．また観測予測についても，状態変数から観測変数を得る関数$h(\cdot)$が既知であるため，アルゴリズム\ref{alg:kalman_estimate}で得られた状態推定値を$h(\cdot)$に入力することで観測予測$\hat{\bm{o}}_t$を得ることができる．
        
            \subsubsection{可変的な観測変数}

            三次元の状態変数を推定するためには，観測変数にも三次元的な情報が含まれなくてはならない．すなわち本問題設定では，複数のスライスにおけるバウンディングボックスがその観測変数に当たる．よって直感的に考えると観測変数は，すべてのスライス$s=1,2,\dots, n_s$におけるバウンディングボックス集合，
            \begin{equation}
                \label{eq:naive_skf_observation}
                    O_t = \left\{\bm{b}_{t, s} \mid s \in \left\{1, 2, \dots, n_s\right\}\right\}
            \end{equation}
            をベクトルにしたものと想定される．
            
            しかしながら式\ref{eq:single_slice_observation_map}からも分かる通り，ある物体が映り込むスライスの数は，その時刻における状態変数$\bm{s}_t$に依存して変化する．また実際には物体検出器から得られるバウンディングボックスが入力になるため，理想的には検出されるはずの情報が抜け落ち，バウンディングボックスの数値が得られるスライスも変化する．

            一方カルマンフィルタにおける状態推定では，観測変数$\bm{o}_t$と観測予測$H_t\bm{\mu}_{t \mid t-1}$の形状が一致していなければならない（式\ref{eq:estimation_equations_with_K}）．これはすなわち，カルマンフィルタの状態推定には，それまでの時刻から予測される推定値と実際の観測値の両方が要求されることを示している．そして本問題においては，あるスライスにおける推定値と観測値が揃っていなければならないと言い換えられる．

            以上の議論によりSliceKalmanFilterでは，時刻$t-1$までの観測変数から推定された時刻$t$の観測変数が存在するスライスと，時刻$t$の観測によって得られた観測変数のスライスとの，共通スライスのみを考慮して観測変数を構築する．時刻$t-1$までの観測変数から推定された時刻$t$のバウンディングボックス集合
            \begin{equation}
                \label{eq:sliced_bounding_boxes}
                \hat{O}_t = \left\{\hat{\bm{b}}_{t, s} \mid  s \in \mathcal{S}_t^{\text{pred}}\right\}
            \end{equation}
            と，時刻$t$で検出されたバウンディングボックス集合を表す
            \begin{equation}
                \label{eq:observed_bounding_boxes}
                O_t = \left\{\bm{b}_{t,s} \mid s \in \mathcal{S}_t^{\text{obs}}\right\}
            \end{equation}
            が得られたと仮定する．ここでは$\mathcal{S}_t^{\text{pred}}$が推定されたバウンディングボックスが存在するスライスの集合，$\mathcal{S}_t^{\text{obs}}$が検出から得られたバウンディングボックスが存在するスライスの集合を表す．最終的な観測変数$\bm{o}_t$はこれらの情報を用いて，
            \begin{equation}
                \label{eq:skf_observation}
                \bm{o}_t = \text{Concat.}\left(\left\{\bm{b}_{t,s} \mid s \in \mathcal{S}_t^{\text{pred}} \cap \mathcal{S}_t^{\text{obs}}\right\}\right)
            \end{equation}
            で表される．ただし，カルマンフィルタの演算はすべてベクトルおよび行列で行われるため，集合を一つのベクトルに結合する操作（Concat.）を行っている．
            
            またこれに応じて状態変数から観測変数を得る観測写像$h(\bm{s}_t)$は式\ref{eq:single_slice_observation_map}を用いて，
            \begin{equation}
                \label{eq:skf_observation_map}
                h(\bm{s}_t) = \text{Concat.}\left(\left\{h_s(\bm{s}_t) \mid s \in \mathcal{S}_t^{\text{pred}} \cap \mathcal{S}_t^{\text{obs}}\right\}\right)
            \end{equation}
            で表される．Concat.を行う理由は同上である．

            \subsubsection{SliceKalmanFilterの初期化}

            \begin{figure}[t]
                \centering
                \includegraphics[width=\linewidth]{fig/bad_initialize.pdf}
                \caption[初期化におけるスライス取得のタイミングの影響]{初期化におけるスライス取得のタイミングの影響．物体が生成される瞬間に，取得されている画像の平面が物体の外側にあれば，上段左のように物体にかかるすべての平面でバウンディングボックスが観測される．しかし生成の瞬間に，その物体が存在する高さの平面における画像が取得されている場合，下段中央のように物体由来のバウンディングボックス集合を途中からしか得られない．}
                \label{fig:bad_initialize}
            \end{figure}

            SORTにおけるカルマンフィルタの初期化，$initial\_estimate$関数（アルゴリズム\ref{alg:kalman_estimate}の初期化）では，式\ref{eq:SORT_kalman_initialize}に示すようにバウンディングボックスの変数を状態変数に代入する処理を行っていた．しかしながら複数のバウンディングボックス集合$O_t$を観測変数に持つSliceKalmanFilterでは，状態変数に直接代入できる変数が観測変数にない．よってSliceKalmanFilterの初期化では，
            \begin{equation}
                \label{eq:SKF_kalman_initialize}
                \begin{aligned}
                    x &= \frac{1}{\left|O_t\right|} \sum_{\bm{b}_{t,s} \in O_t} x_{t,s}
                    \\ y &= \frac{1}{\left|O_t\right|} \sum_{\bm{b}_{t,s} \in O_t} y_{t,s}
                    \\ z &= \frac{\delta z}{\left|O_t\right|} \sum_{\bm{b}_{t,s} \in O_t} s 
                    \\ r &= \frac{1}{2} \max \left(\left\{w_{t,s}, ~ h_{t,s} \mid s \in \mathcal{S}_t^{\text{obs}}\right\}\right)
                \end{aligned}
            \end{equation}
            のように初期化を行う．また速度項についてはSORTと同様に$0$で初期化する．

            さらにSliceKalmanFilterの初期化は，推定の安定を図るために二時刻連続で行う．物体がある時刻で生成されるとき，各高さの画像が取得されるタイミングによっては，図\ref{fig:bad_initialize}のように取得されるバウンディングボックスの情報が不十分になる．これにより，式\ref{eq:SKF_kalman_initialize}において$z$および$r$の推定精度が低くなる．よって十分なバウンディングボックスを利用した推定を行うために，生成された後二時刻分は式\ref{eq:SKF_kalman_initialize}による初期化を行う．

    \subsection{複数スライスに対応したReID}
    \label{subsec:reidentificataion_for_slice}

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/sort_depthsort.pdf}
        \caption[SORT+DepthSORTの概略図]{SORT+DepthSORTの概略図．複数のスライスにおけるバウンディングボックス集合が得られたら，スライスごとの時間方向の対応付け（Time-directional matching）と，深さ方向の対応付け（Depth-directinal matching）を行う．時間方向の対応付けでは，入力バウンディングボックスのうち，いままで追跡してきた物体由来のバウンディングボックスを見つけることができる（上段中央）．一方で深さ方向の対応付けでは，入力バウンディングボックスを個体ごとに仕分けることができる（下段右）．これら二つの処理を統合することで，いままで追跡してきた物体由来のバウンディングボックスをすべて見つけることができる（上段右）．}
        \label{fig:sort_depthsort}
    \end{figure}

    次に，時刻$t$にYOLOから得られた複数の二次元画像に対応するバウンディングボックス集合$B_{t, 1}, B_{t, 2}, \dots, B_{t, n_s}$から各物体の観測集合$\left\{\bm{b}_{t, s} \mid s \in \mathcal{S}_t^{\text{obs}}\right\}$を得るためのReID手法，SORT+DepthSORTの概要を述べる．

    提案するSORT+DepthSORTでは，時刻$t-1$までに，追跡対象である各物体$i$に対して，観測系列
    \begin{equation}
        \label{eq:tracks_on_reid}
        \begin{aligned}
            O^{(i)} &= \left\{\bm{b}_{t',s}^{(i)} \mid (t', s) \in \mathcal{M}^{(i)}\right\}
        \end{aligned}
    \end{equation}
    が得られていると仮定する．ここで$\mathcal{M}^{(i)}$は，各画像を特徴づける時刻とスライスのペアを表す集合であり，この観測系列は時刻$t-1$までにその各画像内で物体$i$に対応付けられたバウンディングボックス集合を表す．すなわち提案するReID手法は，SORTにおいて$\mathcal{M}^{(i)}$が単一のスライスに限定されていたのに対して，$\mathcal{M}^{(i)}$が複数のスライスを含むようにSORTを拡張した手法と言える．これは図\ref{fig:existing_problem}（右）の状況に対応している．

    そしてこれらの観測系列をもとに，スライスごとにSORTと同様の処理，予測と対応付けを行う（\ref{subsubsec:slice_wise_matching}項および図\ref{fig:sort_depthsort}の左上）．これにより，一時的なReIDの結果を得る（図\ref{fig:sort_depthsort}中央上）．またこの一時的なReIDのみでは，時刻$t-1$で検出されていたスライスにおけるバウンディングボックスにしかIDを振ることができない．よってこれとは別に，入力されたバウンディングボックス集合に対して深さ方向にSORTの処理を行うことで，入力されたバウンディングボックスを個体ごとに仕分ける（\ref{subsubsec:depth_directional_matching}項および図\ref{fig:sort_depthsort}下）．この処理をDepthSORTと呼ぶこととする．そして最後に，一時的なReIDの結果と個体ごとに仕分けられたバウンディングボックス集合を統合する（\ref{subsubsec:integration_of_matchings}項および図\ref{fig:sort_depthsort}）ことで，スライスを跨いだReIDを実施する．以降ではそれぞれの処理について詳細に述べる．

        \subsubsection{スライスごとの対応付け}
        \label{subsubsec:slice_wise_matching}

        提案するReIDでは，まず既存手法のSORTと同様の操作をスライスごとに行う．よって追跡している物体$i$の観測系列$O^{(i)}$をスライスごとに分割し，そのスライスごとの観測系列を$kalman\_predict$関数に入力することで，観測予測を得る．ここで用いるカルマンフィルタの状態空間モデルは，SORTと同様にバウンディングボックスをベースにした二次元的な状態空間モデルである．すなわちあるスライス$s$に対して，観測予測集合
        \begin{equation}
            \label{eq:slice_wise_prediction}
            \hat{B}_{t, s} = \left\{kalman\_predict\left(\left\{\bm{b}_{t', s}^{(i)} \mid (t', s) \in \mathcal{M}^{(i)}\right\}, t\right) \mid i \in \mathcal{I}_{t-1}\right\}
        \end{equation}
        を計算する．ここで$\mathcal{I}_{t-1}$は時刻$t-1$時点で追跡している物体のID集合である．
        
        そしてこれらのバウンディングボックスとスライス$s$に相当する観測集合$B_{t,s}$を比較することで対応付けを実施し，一時的にIDが振られた観測集合が得られる．すべてのスライスについてこの対応付けを行うことで得られる観測集合$\mathcal{O}_{\text{sort}}$は，
        \begin{equation}
            \label{eq:sort_identified_bboxes}
            \mathcal{O}_{\text{sort}} = \left\{O_{\text{sort}}^{(i)} \mid i \in \mathcal{I}_{t-1}\right\}
        \end{equation}
        のように表される．$O_{\text{sort}}^{(i)}$は時刻$t$におけるスライスごとの対応付けで物体$i$に対応付けられたバウンディングボックスの集合を表す．
        
        この予測，対応付け，IDを振られたバウンディングボックスの出力，という流れはSORTと完全に一致している．しかしながら，このスライスごとの対応付けのみでは，前時刻$t-1$で検出されたスライスのみでしか新しいバウンディングボックスを得ることができない．すなわち物体が$z$方向に移動している場合は，その動きに追従することができなくなる．そこで提案手法では，次項で説明する深さ方向の対応付けを可能にするDepthSORTという処理を加える．

        \subsubsection{深さ方向に対するSORT適用}
        \label{subsubsec:depth_directional_matching}

        \begin{algorithm}[t]
            \caption[DepthSORT]{DepthSORT}
            \label{alg:depth_sort}
            \begin{algorithmic}[1]
                \Require $\mathcal{B} = \left\{B_s = \left\{\bm{b}_s^{(1)}, \bm{b}_s^{(2)}, \dots\right\} \mid s \in \left\{1, 2, \dots, n_s\right\}\right\}$
                \Ensure $\mathcal{O} = \left\{O^{(i)} \mid i \in \bigcup_{s=1}^{n_s} \mathcal{I}_{s}\right\}$
                \State $\textbf{Initialize: } \mathcal{O}_{\text{act}} = \emptyset,\ \mathcal{O}_{\text{non-act}} = \emptyset,\ \sigma_{\text{act}}$
                \For {$\bm{b}_1^{(j)} \text{ in } B_1$}
                    \State $\text{add } O^{(j)} = \left\{\bm{b}_1^{(j)}\right\} \text{ to } \mathcal{O}_{\text{act}}$
                    \State $\text{add } j \text{ to }\mathcal{I}_1$
                \EndFor
                \For {$s = 2 \text{ to } n_s$}
                    \State $\hat{B}_s = \emptyset$
                    \For {$O^{(i)} \text{ in } \mathcal{O}_{\text{act}}$}
                        \State $\hat{\bm{b}}_s^{(i)} = kalman\_predict(O^{(i)}, t)$
                        \State $\text{add } \hat{\bm{b}}_s^{(i)} \text{ to }\hat{B}_s $
                    \EndFor
                    \State $M_s = hungarian\_matching(\hat{B}_s, B_s)$
                    \For {$(i,j) \text{ in } M_s$}
                        \State $\text{add } \bm{b}_s^{(j)} \text{ to } O^{(i)}$
                        \State $\text{add } i \text{ to } \mathcal{I}_s$
                    \EndFor
                    \For {$i \text{ in } \mathcal{I}_{s-1}$}
                        \State $\sigma_i = calculate\_staleness(i, \mathcal{I}_1, \mathcal{I}_2, \dots, \mathcal{I}_s)$
                        \If {$\sigma_i > \sigma_{\text{act}}$}
                            \State $\text{remove } O^{(i)} \text{ from } \mathcal{O}_{\text{act}}$
                            \State $\text{add } O^{(i)} \text{ to } \mathcal{O}_{\text{non-act}}$
                        \EndIf
                    \EndFor
                \EndFor
                \State \Return $\mathcal{O}_{\text{act}} \cup \mathcal{O}_{\text{non-act}}$
            \end{algorithmic}
        \end{algorithm}

        SORTでは時間方向に画像から検出されたバウンディングボックスを比較し，同じ個体由来のバウンディングボックス同士を対応付けていた．よってスライスを跨いだ対応付けを行うためには，ある時刻$t$における$n_s$枚のスライスを時系列データとみなして，SORTを実施すれば良い．この操作をDepthSORTと呼ぶことにする．DepthSORTにより，時刻$t$におけるReIDへの入力$B_{t, 1}, B_{t,2}, \dots, B_{t, n_s}$に含まれるバウンディングボックスを，由来する個体ごとに分けられた集合に分けることができる．ここでは前述のスライスごとの対応付けの結果と区別するため，この集合を，
        \begin{equation}
            \label{eq:dsort_identified_bboxes}
            \mathcal{O}_{\text{d-sort}} = \left\{O_{\text{d-sort}}^{(i)} \mid i \in \mathcal{I}_{t}^{\text{d-sort}}\right\}
        \end{equation}
        と表す．ここで$\mathcal{I}_t^{\text{d-sort}}$は仕分けられた各個体のIDを示すが，時刻$t-1$までに追跡してきたIDとは関係ないIDであることに注意されたい．

        DepthSORTの処理をアルゴリズム\ref{alg:depth_sort}に示す．DepthSORTのアルゴリズムはほとんどがSORT（アルゴリズム\ref{alg:sort}）と同様であるが，異なる点が三点ある．まず一つ目に，入力バウンディングボックス系列が時間に関する系列ではなく，スライスに関する系列（一行目および6行目）であることである．そして二つ目に，出力には閾値$\sigma_{\text{act}}$によって打ち切られた軌跡が含まれることである．SORTではリアルタイム追跡を行っていたため，最新時刻$t$時点で追跡が打ち切られている物体には基本的には興味がない．しかしながらDepthSORTの場合は，打ち切られた軌跡は過去のものではなく，単に検出された物体の位置が低いことを示しているだけである．よってDepthSORTでは打ち切られた軌跡$\mathcal{O}_{\text{act}}$も出力する（21行目および25行目）．また三つ目に，軌跡の打ち切りタイミングを調整する$\sigma_{\text{act}}$のスケールが異なることである．

        SORTにおける$\sigma_{\text{act}} = 1$は，ある時刻に対応付けが一度も起きなくても，フレーム間隔$\delta t$後の次の時刻において一つでも対応付けがあれば，追跡を続けられることを意味する．しかしDepthSORTにおける$\sigma_{\text{act}} = 1$は，ある物体由来のバウンディングボックスを2スライス連続で見逃したときに，その上側と下側のバウンディングボックスが他の物体として認識されることを意味する．これは非常に厳格な閾値になるため，通常はSORTにおける閾値の値よりも大きく設定したほうがよい．具体的な値については，後述の\ref{sec:demodata}節で述べる．
        
        \subsubsection{時間方向の対応付けと深さ方向の対応付けの統合}
        \label{subsubsec:integration_of_matchings}

        DepthSORTの出力はスライスを跨いだ対応付けを可能にしていたが，ここで振り分けられた各IDと，時刻$t-1$までに追跡されてきた物体のIDは関連していない．よって最後に，この深さ方向から得られたReID情報と時間方向から得られたReID情報の統合を行い，SliceKalmanFilterへの出力を得るアルゴリズムを説明する．

        最終的な統合では，DepthSORTによって得られたReID情報に対して，時刻$t-1$までに追跡してきたID集合$\mathcal{I}_{t-1}$のIDを再度振り直し，そのReID情報を出力する．これはすなわち，スライスごとの対応付けで用いたID集合$\mathcal{I}_{t-1}$と，DepthSORTの結果におけるID集合$\mathcal{I}_t^{\text{d-sort}}$間の対応付けと考えることができる．よってこの問題を割当問題として考え，アルゴリズム\ref{alg:hungarian_matching}を利用することで最適化する．
        また要素間の類似度を出力する関数は，共通するバウンディングボックスの個数とする．すなわち$O_{\text{sort}}^{(i)}$と$O_{\text{d-sort}}^{(j)}$の二つの集合の類似度は，$f_{\text{sim}}(O_{\text{sort}}^{(i)}, O_{\text{d-sort}}^{(j)}) = \left| O_{\text{sort}}^{(i)}\cap O_{\text{d-sort}}^{(j)}\right|$となる．
        
        \subsubsection{SORT+DepthSORTのアルゴリズム}

        \begin{algorithm}[t]
            \caption{SORT+DepthSORT}
            \label{alg:sort_depthsort}
            \small
            \begin{algorithmic}[1]
                \Require $\mathcal{B} = \left\{B_{t,s} = \left\{\bm{b}_{t,s}^{(1)}, \bm{b}_{t,s}^{(2)}, \dots\right\} \mid t \in \left\{1, 2, \dots, T\right\}, s \in \left\{1, 2, \dots, n_s\right\}\right\}$
                \Ensure $\mathcal{O}_T = \left\{O^{(i)} \mid i \in \mathcal{I}_t\right\}$
                \State $\textbf{Initialize: } \sigma_{\text{act}},\ \mathcal{O}_{\text{sort}}, \mathcal{O}_{\text{d-sort}}$
                \State $\mathcal{O}_1 = depth\_sort(\left\{B_{t, s} \mid s \in \left\{1, 2, \dots, n_s\right\}\right\})$
                \State $\mathcal{I}_1 = \left\{i \mid O^{(i)} \in \mathcal{O}_1\right\}$
                \For {$t = 2 \text{ to } T$}
                    \State $\mathcal{O}_t = \emptyset,\ \mathcal{O}_{\text{sort}} \gets \emptyset,\ \mathcal{O}_{\text{d-sort}} \gets \emptyset$
                    \For {$s = 1 \text{ to } n_s$}
                        \State $\hat{B}_{t,s} = \emptyset$
                        \For {$O^{(i)} \text{ in } \mathcal{O}_{t-1}$}
                            \State $\hat{\bm{b}}_{t,s}^{(i)} = kalman\_predict\left(\left\{\bm{b}_{t',s'}^{(i)} \mid \bm{b}_{t',s'}^{(i)} \in O^{(i)} , ~ s' = s\right\}, t\right)$
                            \State $\text{add } \hat{\bm{b}}_{t,s}^{(i)} \text{ to }\hat{B}_{t,s}$
                        \EndFor
                        \State $M_{t,s} = hungarian\_matching(\hat{B}_{t,s}, B_{t,s})$
                        \For {$(i,j) \text{ in } M_{t,s}$}
                            \If {$O_{\text{sort}}^{(i)} \text{ is undefined}$}
                                \State $\text{add } O_{\text{sort}}^{(i)} = \left\{\bm{b}_{t,s}^{(j)}\right\} \text{ to } \mathcal{O}_{\text{sort}}$
                            \Else
                                \State $\text{add } \bm{b}_{t,s}^{(j)} \text{ to } O_{\text{sort}}^{(i)}$
                            \EndIf
                        \EndFor
                    \EndFor 
                    \State $\mathcal{O}_{\text{d-sort}} \gets depth\_sort\left(\left\{B_{t',s} \mid B_{t',s} \in \mathcal{B} , ~ t' = t\right\}\right)$
                    \State $M_t = hungarian\_matching(\mathcal{O}_{\text{sort}}, \mathcal{O}_{\text{d-sort}})$
                    \For {$(i,j) \text{ in } M_t$}
                        \State $O^{(i)} \gets O^{(i)} \cup O_{\text{d-sort}}^{(j)}$
                        \State $\text{add } O^{(i)} \text{ to } \mathcal{O}_t $
                        \State $\text{add } i \text{ to } \mathcal{I}_t$
                    \EndFor
                    \For {$i \text{ in } \mathcal{I}_{t-1}$}
                        \State $\sigma_i = calculate\_staleness(i, \mathcal{I}_1, \mathcal{I}_2, \dots, \mathcal{I}_t)$
                        \If {$\sigma_i \leq \sigma_{\text{act}}$}
                            \State $\text{add } O^{(i)} \text{ to } \mathcal{O}_t$
                        \EndIf
                    \EndFor
                \EndFor
                \State \Return $\mathcal{O}_T$
            \end{algorithmic}
        \end{algorithm}

        SORT+DepthSORTによる，時刻$t$までの各画像に対応するバウンディングボックス集合の系列データ$\mathcal{B}$が得られたときに，IDごとに，各IDに割り当てられたバウンディングボックス集合を返すReIDの処理をアルゴリズム\ref{alg:sort_depthsort}に示す（ここではSliceKalmanFilterによる状態推定を含んでいないことに注意されたい）．

        時刻$t$のスライス二次元画像から検出されたバウンディングボックス集合$B_{t, 1}, B_{t, 2}, \dots, B_{t, n_s}$が得られたら，まずはスライスごとの予測および対応付けを行う（アルゴリズム6-20行目）．この予測は，各スライスで検出された時刻$t-1$までのバウンディングボックスを，二次元的な状態空間モデルのカルマンフィルタに入力することによって行われる（アルゴリズム9行目）．これによって，一時的なIDが割り振られたバウンディングボックス集合$\mathcal{O}_{\text{sort}}$が得られる（アルゴリズム15行目および17行目）．

        そしてこのスライスごとの対応付けとは別に，バウンディングボックス集合$B_{t, 1}, B_{t, 2}, \dots, B_{t, n_s}$を入力としたDepthSORTを行う（アルゴリズム21行目）．この操作により，入力されたバウンディングボックス集合を個体ごとに仕分けた$\mathcal{O}_{\text{d-sort}}$が得られる．

        そして最後に，時刻$t-1$までのIDが割り振られた$\mathcal{O}_{\text{sort}}$と個体ごとにIDが振られた$\mathcal{O}_{\text{d-sort}}$の間で対応付けを行い，結果に応じて更新・生成・削除を行う（アルゴリズム22-33行目）．ただしアルゴリズムでは，例にならい生成の処理を省略した．DepthSORTを利用したReIDにより，別の個体由来のバウンディングボックスが対応付けられる事態を抑えながら，他のスライスへの対応付けを可能にしている．

        \subsubsection{その他のReID手法の選択肢}

        \begin{table}[t]
            \centering
            \caption[ReID手法の選択肢]{ReID手法の選択肢．観測予測手法が二次元の場合はバウンディングボックスをベースとした状態変数，三次元の場合は三次元球体をベースとした状態変数から観測予測が行われる．また更新時にDepthSORTを用いる場合は，深さ方向の対応付けによって得られたReID情報が状態更新に使用される．}
            \label{tab:reidentification_methods}
            \begin{tabular}{l|cc}
                Mode &  観測予測手法 & 更新時に用いるReID
                \\ \hline \hline
                SORT + DepthSORT & 二次元 & DepthSORT
                \\ SKF + DepthSORT & 三次元 & DepthSORT
                \\ only SKF & 三次元 & スライスごと 
            \end{tabular}
        \end{table}

        前述のSORT+DepthSORTでは，既存手法のSORTでも用いられていたようなバウンディングボックスに対応する状態変数（式\ref{eq:sort_state_vector}）を対応付けに利用していた．しかしながら提案手法では状態推定用のカルマンフィルタ，SliceKalmanFilterがあるため，これを用いた観測予測を利用することも可能である．また特に$z$方向への速度が大きい場合には，三次元的な情報を考慮できるSliceKalmanFilterのほうがより精度の高い観測予測を行える可能性がある．よって別のReID手法として，スライスごとの対応付けにおいてSliceKalmanFilterの観測予測を用いる手法も提案する．
        
        さらにまた別手法として，そもそもDepthSORTによって得られたReID情報を更新に用いないことも考えられる．この場合は時刻$t$の対応付けにおいて時刻$t-1$までに三次元的な観測変数を得なければならない．よってこの手法では，スライスごとの対応付けにはSliceKalmanFilterを利用し，新しいID生成にはDepthSORTを用いる．ただしこの生成に用いるバウンディングボックス集合は，更新時に利用されたバウンディングボックスを一つも含まないバウンディングボックス集合であるとする．

        またDepthSORTを更新に用いない手法として，時間方向の対応付けにSORTを用いて，その結果を更新に利用する手法も考えられる．しかしながらこの手法は前述したように，時刻$t-1$において検出バウンディングボックスが存在するスライスでしか対応付けが行われず，深さ方向の挙動を追跡できない．よってこの手法は提案手法に含めない．

        以上のReID手法を表\ref{tab:reidentification_methods}にまとめる．表における``観測予測手法"とは，スライスごとの対応付けにおける予測手法のことを表す．``二次元"の場合はSORTのようなバウンディングボックスの状態変数（式\ref{eq:sort_state_vector}）を用い，``三次元''の場合はSliceKalmanFilterおよび三次元的な状態変数（式\ref{eq:skf_state_vector}）を使用する．また``更新時に用いるReID''とは，DepthSORTから得られたReIDとの対応付けを行うかどうかを示している．``スライスごと''である場合は，スライスごとに対応付けされたバウンディングボックス集合$\mathcal{O}_{\text{sort}}$をそのまま観測変数としてSliceKalmanFilterの更新に用いる．一方``DepthSORT''の場合は，ID間の対応付けを行い，DepthSORTから得られた個体ごとのバウンディングボックス集合$\mathcal{O}_{\text{d-sort}}$を利用してSliceKalmanFilterの観測変数を取得する．